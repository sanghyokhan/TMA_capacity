{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed48b304",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "643a132f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T07:44:36.179754Z",
     "start_time": "2021-07-27T07:44:36.156721Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna.integration.lightgbm as lgb          ####\n",
    "from lightgbm import LGBMRegressor, plot_metric    #### 여기서 lgb로 안가져옴\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score, max_error, mean_absolute_error, mean_squared_log_error, mean_absolute_percentage_error, median_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01cd179e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T07:33:54.921717Z",
     "start_time": "2021-07-27T07:33:54.848992Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# options\n",
    "pd.set_option('max_columns',100)\n",
    "plt.style.use('fivethirtyeight')\n",
    "warnings.simplefilter('ignore')\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5aff956",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T07:33:55.941887Z",
     "start_time": "2021-07-27T07:33:55.915701Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data dirctory\n",
    "data_dir = Path('../data/')\n",
    "data_file = data_dir / 'data.csv'\n",
    "input_dir = Path('../input/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "750ec8d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T07:33:57.152881Z",
     "start_time": "2021-07-27T07:33:57.143355Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "# 0:AAR / 1:EAD / 2:ADR / 3:EDD는 고정  , 나머지는 순서 상관 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92a3108e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T07:33:59.819375Z",
     "start_time": "2021-07-27T07:33:58.246462Z"
    }
   },
   "outputs": [],
   "source": [
    "Data = pd.read_csv(data_file, index_col=0)\n",
    "Data_6 = pd.read_csv(data_dir / 'data_6.csv' , index_col=0)\n",
    "Data_12 = pd.read_csv(data_dir / 'data_12.csv', index_col=0)\n",
    "Data_18 = pd.read_csv(data_dir / 'data_18.csv', index_col=0)\n",
    "Data_24 = pd.read_csv(data_dir / 'data_24.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50041d29",
   "metadata": {},
   "source": [
    "Validation <br><br>\n",
    "\n",
    "sklearn.model_selection\n",
    "* train_test_split\n",
    "* KFold\n",
    "* StratifiedKFold\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "lightGBM <br>\n",
    "* lgb.cv    # 쓰려면 lightgbm을 lgb로 import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69db9d5",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef3c018",
   "metadata": {},
   "source": [
    "# LightGBM fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945f29bb",
   "metadata": {},
   "source": [
    "## Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12b62e89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T07:36:06.246202Z",
     "start_time": "2021-07-27T07:36:05.866348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data shape :  (17520, 46)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EAD</th>\n",
       "      <th>EDD</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>DayName</th>\n",
       "      <th>Arpt_cond</th>\n",
       "      <th>P_Airp</th>\n",
       "      <th>P_AAR</th>\n",
       "      <th>P_ADR</th>\n",
       "      <th>Arrival_remainder</th>\n",
       "      <th>Departure_remainder</th>\n",
       "      <th>WD_850</th>\n",
       "      <th>WD_925</th>\n",
       "      <th>WD_1000</th>\n",
       "      <th>WS_850</th>\n",
       "      <th>WS_925</th>\n",
       "      <th>WS_1000</th>\n",
       "      <th>WD</th>\n",
       "      <th>WSPD</th>\n",
       "      <th>WS_GST</th>\n",
       "      <th>VIS</th>\n",
       "      <th>WC</th>\n",
       "      <th>RN</th>\n",
       "      <th>CA_TOT</th>\n",
       "      <th>CLA_1LYR</th>\n",
       "      <th>BASE_1LYR</th>\n",
       "      <th>CLA_2LYR</th>\n",
       "      <th>BASE_2LYR</th>\n",
       "      <th>CLA_3LYR</th>\n",
       "      <th>BASE_3LYR</th>\n",
       "      <th>CLA_4LYR</th>\n",
       "      <th>BASE_4LYR</th>\n",
       "      <th>RVR</th>\n",
       "      <th>WDIR_t6</th>\n",
       "      <th>WSPD_t6</th>\n",
       "      <th>WG_t6</th>\n",
       "      <th>VIS_t6</th>\n",
       "      <th>WC_t6</th>\n",
       "      <th>CLA_1LYR_t6</th>\n",
       "      <th>BASE_1LYR_t6</th>\n",
       "      <th>CLA_2LYR_t6</th>\n",
       "      <th>BASE_2LYR_t6</th>\n",
       "      <th>CLA_3LYR_t6</th>\n",
       "      <th>BASE_3LYR_t6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    EAD   EDD  year  month  day  hour  DayName  Arpt_cond  P_Airp  P_AAR  \\\n",
       "0   2.0  11.0  2018      1    1     0        1        1.0     1.0    0.0   \n",
       "1   1.0   5.0  2018      1    1     1        1        1.0     1.0    3.0   \n",
       "2   1.0   4.0  2018      1    1     2        1        1.0     1.0    0.0   \n",
       "3   0.0   1.0  2018      1    1     3        1        1.0     1.0    0.0   \n",
       "4  16.0   1.0  2018      1    1     4        1        1.0     1.0    2.0   \n",
       "\n",
       "   P_ADR  Arrival_remainder  Departure_remainder  WD_850  WD_925  WD_1000  \\\n",
       "0    0.0                0.0                  0.0   320.0   325.0    245.0   \n",
       "1   11.0                0.0                  0.0   320.0   325.0    245.0   \n",
       "2    4.0                1.0                  1.0   320.0   325.0    245.0   \n",
       "3    4.0                1.0                  0.0   320.0   325.0    245.0   \n",
       "4    1.0                0.0                  0.0   320.0   325.0    245.0   \n",
       "\n",
       "   WS_850  WS_925  WS_1000  WD  WSPD  WS_GST   VIS  WC   RN  CA_TOT  CLA_1LYR  \\\n",
       "0    28.0    19.0      3.0  34     5     0.0  1000   1  0.0       0       0.0   \n",
       "1    28.0    19.0      3.0   3     1     0.0  1000   1  0.0       0       0.0   \n",
       "2    28.0    19.0      3.0  35     1     0.0  1000   1  0.0       0       0.0   \n",
       "3    28.0    19.0      3.0   0     0     0.0  1000   1  0.0       0       0.0   \n",
       "4    28.0    19.0      3.0  19     1     0.0  1000   1  0.0       0       0.0   \n",
       "\n",
       "   BASE_1LYR  CLA_2LYR  BASE_2LYR  CLA_3LYR  BASE_3LYR  CLA_4LYR  BASE_4LYR  \\\n",
       "0      400.0       0.0      400.0       0.0      400.0       0.0      400.0   \n",
       "1      400.0       0.0      400.0       0.0      400.0       0.0      400.0   \n",
       "2      400.0       0.0      400.0       0.0      400.0       0.0      400.0   \n",
       "3      400.0       0.0      400.0       0.0      400.0       0.0      400.0   \n",
       "4      400.0       0.0      400.0       0.0      400.0       0.0      400.0   \n",
       "\n",
       "      RVR  WDIR_t6  WSPD_t6  WG_t6  VIS_t6  WC_t6  CLA_1LYR_t6  BASE_1LYR_t6  \\\n",
       "0  1000.0      0.0      0.0    0.0  9999.0      0            0         400.0   \n",
       "1  1000.0      0.0      0.0    0.0  9999.0      0            0         400.0   \n",
       "2  1000.0      0.0      0.0    0.0  9999.0      0            0         400.0   \n",
       "3  1000.0      0.0      0.0    0.0  9999.0      0            0         400.0   \n",
       "4  1000.0      0.0      0.0    0.0  9999.0      0            0         400.0   \n",
       "\n",
       "   CLA_2LYR_t6  BASE_2LYR_t6  CLA_3LYR_t6  BASE_3LYR_t6  \n",
       "0            0         400.0            0         400.0  \n",
       "1            0         400.0            0         400.0  \n",
       "2            0         400.0            0         400.0  \n",
       "3            0         400.0            0         400.0  \n",
       "4            0         400.0            0         400.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측할 시간에 맞는 Data로 넣기\n",
    "# 0-6 : Data_6 / 6-12 : Data_12 / 12-18 : Data_18 / 18-24 : Data_24\n",
    "Data_raw = Data_6\n",
    "Data_m = Data_6\n",
    "Data_m = Data_m.drop('AAR', axis=1)\n",
    "Data_m = Data_m.drop('ADR', axis=1)\n",
    "\n",
    "\n",
    "# Arrival\n",
    "y_a = Data_raw.AAR.to_numpy()\n",
    "X_a = Data_m.to_numpy()\n",
    "#X_train_a, X_test_a, y_train_a, y_test_a = train_test_split(X_a, y_a, test_size = 0.1, random_state = seed)\n",
    "X_train_a, X_test_a, y_train_a, y_test_a = train_test_split(X_a, y_a, test_size = 0.1, random_state = seed)\n",
    "X_train_a, X_val_a, y_train_a, y_val_a = train_test_split(X_train_a, y_train_a, test_size=0.11, random_state = 13) \n",
    "\n",
    "\n",
    "# Departure\n",
    "y_d = Data_raw.ADR.to_numpy()\n",
    "X_d = Data_m.to_numpy()\n",
    "#X_train_d, X_test_d, y_train_d, y_test_d = train_test_split(X_d, y_d, test_size = 0.1, random_state = seed)\n",
    "X_train_d, X_test_d, y_train_d, y_test_d = train_test_split(X_d, y_d, test_size = 0.1, random_state = seed)\n",
    "X_train_d, X_val_d, y_train_d, y_val_d = train_test_split(X_train_d, y_train_d, test_size=0.11, random_state = 13) \n",
    "\n",
    "# val은 hyperparameter 검증에 사용\n",
    "# 0.11 x 0.9 = 0.099\n",
    "\n",
    "print('Training Data shape : ', Data_m.shape)\n",
    "Data_m.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da30602",
   "metadata": {},
   "source": [
    "***\n",
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3e435c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T07:36:07.992612Z",
     "start_time": "2021-07-27T07:36:07.966538Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "params = {'boosting_type' : 'gbdt',            # 'dart' 는 계산시간 길어짐, early stopping X / 'rf’ : Random Forest\n",
    "          'metric': 'mse',\n",
    "          'num_leaves' : 127,                  ## Maximum tree leaves for base learners (31)\n",
    "          'max_depth' : - 1,                   # Maximum tree depth for base learners, <=0 means no limit (-1)\n",
    "          'learning_rate' : 0.001,             ## Boosting learning rate (0.1)\n",
    "          'n_estimators' : 10000000,           # Number of boosted trees to fit (100) -> fit에서 early stopping으로 제한해서 크게 설정함\n",
    "          'subsample_for_bin' : 200000,        # Number of samples for constructing bins (200000)\n",
    "          'objective' : 'regression',          # learning task and the corresponding learning objective (None)\n",
    "          'class_weight' : None,               # * Use this parameter only for multi-class classification task\n",
    "          'min_split_gain' : 0.0,              # Minimum loss reduction required to make a further partition on a leaf node of the tree (0)\n",
    "          'min_child_weight' : 0.001,          # Minimum sum of instance weight (hessian) needed in a child (leaf) (0.001)\n",
    "          'min_child_samples' : 1,             # Minimum number of data needed in a child (leaf) (20) - 마지막노드(리프)에 최소 몇가지 샘플이 있어야 하는지 \n",
    "          'subsample' : 0.8,                   ## Subsample ratio of the training instance (1.0) - 개별 트리를 학습시키는데 몇 %의 데이터를 사용할 것 인지, row sampling\n",
    "          'subsample_freq' : 1,                # Frequency of subsample, <=0 means no enable (0) - 몇개의 트리마다 subsampling을 할 것인지\n",
    "          'colsample_bytree' : 0.8,            ## Subsample ratio of columns when constructing each tree (1.0) - 몇 %의 column을 sampling 할 것인지\n",
    "          'reg_alpha' : 0.0,                   # L1 regularization term on weights (0)\n",
    "          'reg_lambda' : 0.0,                  # L2 regularization term on weights (0)\n",
    "          'random_state' : seed,               # Random number seed (None)\n",
    "          'n_jobs' : - 1,                      # Number of parallel threads (-1) - 몇 개의 병렬작업을 할 것인지 (-1 = 모든 가능한 것 전부)\n",
    "          'silent' : True,                     # Whether to print messages while running boosting (True)\n",
    "          'importance_type' : 'split'}         # ‘split’: result contains numbers of times the feature is used in a model\n",
    "                                               # ‘gain’ : result contains total gains of splits which use the feature\n",
    "\n",
    "# 최적 hyperparameter 찾기!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "706352d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T07:36:09.958587Z",
     "start_time": "2021-07-27T07:36:09.931056Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters - arrival\n",
    "params_a = {'boosting_type' : 'gbdt',                   # 'dart' 는 계산시간 길어짐, early stopping X / 'rf’ : Random Forest\n",
    "            'metric': 'mse',\n",
    "            'num_leaves' : 127,                          ## Maximum tree leaves for base learners (31)\n",
    "            'max_depth' : - 1,                          # Maximum tree depth for base learners, <=0 means no limit (-1)\n",
    "            'learning_rate' : 0.001,                    ## Boosting learning rate (0.1)\n",
    "            'n_estimators' : 1000000,                   # Number of boosted trees to fit (100) -> fit에서 early stopping으로 제한해서 크게 설정함\n",
    "            'subsample_for_bin' : 200000,               # Number of samples for constructing bins (200000)\n",
    "            'objective' : 'regression',                 # learning task and the corresponding learning objective (None)\n",
    "            'class_weight' : None,                      # * Use this parameter only for multi-class classification task\n",
    "            'min_split_gain' : 0.0,                     # Minimum loss reduction required to make a further partition on a leaf node of the tree (0)\n",
    "            'min_child_weight' : 0.001,                 # Minimum sum of instance weight (hessian) needed in a child (leaf) (0.001)\n",
    "            'min_child_samples' : 1,                    # Minimum number of data needed in a child (leaf) (20) - 마지막노드(리프)에 최소 몇가지 샘플이 있어야 하는지 \n",
    "            'feature_pre_filter': False,\n",
    "            'subsample' : 0.98,           ## Subsample ratio of the training instance (1.0) - 개별 트리를 학습시키는데 몇 %의 데이터를 사용할 것 인지, row sampling\n",
    "            'subsample_freq' : 1,   #3                  # Frequency of subsample, <=0 means no enable (0) - 몇개의 트리마다 subsampling을 할 것인지\n",
    "            'colsample_bytree' : 0.72,    ## Subsample ratio of columns when constructing each tree (1.0) - 몇 %의 column을 sampling 할 것인지\n",
    "            'reg_alpha' : 1.5174152626537185,       # L1 regularization term on weights (0)\n",
    "            'reg_lambda' : 5.0986611213704176e-06,           # L2 regularization term on weights (0)\n",
    "            'random_state' : seed,                      # Random number seed (None)\n",
    "            'n_jobs' : - 1,                             # Number of parallel threads (-1) - 몇 개의 병렬작업을 할 것인지 (-1 = 모든 가능한 것 전부)\n",
    "            'silent' : True,                            # Whether to print messages while running boosting (True)\n",
    "            'importance_type' : 'split'}                # ‘split’: result contains numbers of times the feature is used in a model\n",
    "                                                        # ‘gain’ : result contains total gains of splits which use the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faf8758",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T03:11:30.154484Z",
     "start_time": "2021-07-27T02:37:57.328921Z"
    }
   },
   "outputs": [],
   "source": [
    "# Optuna 간단 버전 - arrival\n",
    "\n",
    "\"\"\"y = Data_raw.AAR.to_numpy()\n",
    "X = Data_m.to_numpy()\n",
    "\n",
    "X_train_a, X_val_a, y_train_a, y_val_a = train_test_split(X, y, test_size=.2, random_state=seed)\n",
    "\n",
    "dtrain_a = lgb.Dataset(X_train_a, label = y_train_a)\n",
    "dval_a = lgb.Dataset(X_val_a, label = y_val_a)\n",
    "\n",
    "model = lgb.train(params, dtrain_a,\n",
    "                  valid_sets=[dtrain_a, dval_a], \n",
    "                  verbose_eval=100,\n",
    "                  early_stopping_rounds=10)\n",
    "\n",
    "prediction = model.predict(X_val_a, num_iteration=model.best_iteration)\n",
    "\n",
    "accuracy = r2_score(y_val_a, prediction)        # classification이면 앞에 argmax( , axis = 1)로 하면 될 듯\n",
    "\n",
    "\n",
    "\n",
    "params = model.params\n",
    "print(\"Best params:\", params)\n",
    "print(\"  Accuracy = {}\".format(accuracy))\n",
    "print(\"  Params: \")\n",
    "for key, value in params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "params_a = params\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eac52ee7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T07:36:17.580230Z",
     "start_time": "2021-07-27T07:36:17.561712Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters - departure\n",
    "params_d = {'boosting_type' : 'gbdt',                 # 'dart' 는 계산시간 길어짐, early stopping X / 'rf’ : Random Forest\n",
    "            'metric': 'mse',\n",
    "            'num_leaves' : 127,                        ## Maximum tree leaves for base learners (31)\n",
    "            'max_depth' : - 1,                        # Maximum tree depth for base learners, <=0 means no limit (-1)\n",
    "            'learning_rate' : 0.001,                  ## Boosting learning rate (0.1)\n",
    "            'n_estimators' : 1000000,                 # Number of boosted trees to fit (100) -> fit에서 early stopping으로 제한해서 크게 설정함\n",
    "            'subsample_for_bin' : 200000,             # Number of samples for constructing bins (200000)\n",
    "            'objective' : 'regression',               # learning task and the corresponding learning objective (None)\n",
    "            'class_weight' : None,                    # * Use this parameter only for multi-class classification task\n",
    "            'min_split_gain' : 0.0,                   # Minimum loss reduction required to make a further partition on a leaf node of the tree (0)\n",
    "            'min_child_weight' : 0.001,               # Minimum sum of instance weight (hessian) needed in a child (leaf) (0.001)\n",
    "            'min_child_samples' : 1,                  # Minimum number of data needed in a child (leaf) (20) - 마지막노드(리프)에 최소 몇가지 샘플이 있어야 하는지 \n",
    "            'feature_pre_filter': False,\n",
    "            'subsample' : 0.99,         ## Subsample ratio of the training instance (1.0) - 개별 트리를 학습시키는데 몇 %의 데이터를 사용할 것 인지, row sampling\n",
    "            'subsample_freq' : 1,    #3               # Frequency of subsample, <=0 means no enable (0) - 몇개의 트리마다 subsampling을 할 것인지\n",
    "            'colsample_bytree' : 0.8,  ## Subsample ratio of columns when constructing each tree (1.0) - 몇 %의 column을 sampling 할 것인지\n",
    "            'reg_alpha' :  1.4025647727814503,     # L1 regularization term on weights (0)\n",
    "            'reg_lambda' : 1.0819342779766032e-08,      # L2 regularization term on weights (0)\n",
    "            'random_state' : seed,                    # Random number seed (None)\n",
    "            'n_jobs' : - 1,                           # Number of parallel threads (-1) - 몇 개의 병렬작업을 할 것인지 (-1 = 모든 가능한 것 전부)\n",
    "            'silent' : True,                          # Whether to print messages while running boosting (True)\n",
    "            'importance_type' : 'split'}              # ‘split’: result contains numbers of times the feature is used in a model\n",
    "                                                      # ‘gain’ : result contains total gains of splits which use the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95a4d4b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T07:36:21.958171Z",
     "start_time": "2021-07-27T07:36:21.922123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y = Data_raw.ADR.to_numpy()\\nX = Data_m.to_numpy()\\n\\nX_train_d, X_val_d, y_train_d, y_val_d = train_test_split(X, y, test_size=.2, random_state=seed)\\n\\ndtrain_d = lgb.Dataset(X_train_d, label = y_train_d)\\ndval_d = lgb.Dataset(X_val_d, label = y_val_d)\\n\\nmodel = lgb.train(params, dtrain_d,\\n                  valid_sets=[dtrain_d, dval_d], \\n                  verbose_eval=100,\\n                  early_stopping_rounds=10)\\n\\nprediction = model.predict(X_val_d, num_iteration=model.best_iteration)\\n\\naccuracy = r2_score(y_val_d, prediction)         # classification이면 앞에 argmax( , axis = 1)로 하면 될 듯\\n\\nparams = model.params\\nprint(\"Best params:\", params)\\nprint(\"  Accuracy = {}\".format(accuracy))\\nprint(\"  Params: \")\\nfor key, value in params.items():\\n    print(\"    {}: {}\".format(key, value))\\n\\nparams_d = params'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optuna 간단 버전 - departure\n",
    "\n",
    "\n",
    "\"\"\"y = Data_raw.ADR.to_numpy()\n",
    "X = Data_m.to_numpy()\n",
    "\n",
    "X_train_d, X_val_d, y_train_d, y_val_d = train_test_split(X, y, test_size=.2, random_state=seed)\n",
    "\n",
    "dtrain_d = lgb.Dataset(X_train_d, label = y_train_d)\n",
    "dval_d = lgb.Dataset(X_val_d, label = y_val_d)\n",
    "\n",
    "model = lgb.train(params, dtrain_d,\n",
    "                  valid_sets=[dtrain_d, dval_d], \n",
    "                  verbose_eval=100,\n",
    "                  early_stopping_rounds=10)\n",
    "\n",
    "prediction = model.predict(X_val_d, num_iteration=model.best_iteration)\n",
    "\n",
    "accuracy = r2_score(y_val_d, prediction)         # classification이면 앞에 argmax( , axis = 1)로 하면 될 듯\n",
    "\n",
    "params = model.params\n",
    "print(\"Best params:\", params)\n",
    "print(\"  Accuracy = {}\".format(accuracy))\n",
    "print(\"  Params: \")\n",
    "for key, value in params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "params_d = params\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4778b3",
   "metadata": {},
   "source": [
    "***\n",
    "## Arrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed11e024",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T07:36:57.696443Z",
     "start_time": "2021-07-27T07:36:43.998576Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-87c25adb4406>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mreg_arrival\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLGBMRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams_a\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m reg_arrival.fit(X_train_a, y_train_a,\n\u001b[0m\u001b[0;32m      5\u001b[0m                 \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m                   \u001b[1;31m# Weights of training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                 \u001b[0minit_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m                      \u001b[1;31m# Weights of training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py01\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    816\u001b[0m             callbacks=None, init_model=None):\n\u001b[0;32m    817\u001b[0m         \u001b[1;34m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 818\u001b[1;33m         super().fit(X, y, sample_weight=sample_weight, init_score=init_score,\n\u001b[0m\u001b[0;32m    819\u001b[0m                     \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_sample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m                     \u001b[0meval_init_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_init_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py01\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    681\u001b[0m             \u001b[0minit_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbooster_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 683\u001b[1;33m         self._Booster = train(params, train_set,\n\u001b[0m\u001b[0;32m    684\u001b[0m                               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_sets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_sets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py01\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py01\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   2641\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2642\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot update due to null objective function.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2643\u001b[1;33m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[0;32m   2644\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2645\u001b[0m                 ctypes.byref(is_finished)))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model fitting\n",
    "reg_arrival = LGBMRegressor(**params_a)\n",
    "\n",
    "reg_arrival.fit(X_train_a, y_train_a,\n",
    "                sample_weight = None,                   # Weights of training data\n",
    "                init_score = None,                      # Weights of training data\n",
    "                eval_set = [(X_val_a, y_val_a)],        # pairs to use as validation sets\n",
    "                eval_sample_weight = None,              # Weights of eval data\n",
    "                eval_init_score = None,                 # Init score of eval data.   \n",
    "                eval_metric = 'l2',                     # Default: ‘l2’ for LGBMRegressor, ‘logloss’ for LGBMClassifier\n",
    "                early_stopping_rounds = 10,             # loss fuction이 n번 이상 좋아지지 않으면 멈춰라\n",
    "                verbose = False)            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569e4655",
   "metadata": {},
   "source": [
    "***\n",
    "##  Departure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f395c91a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T07:36:57.705446Z",
     "start_time": "2021-07-27T07:36:44.724Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model fitting\n",
    "reg_departure = LGBMRegressor(**params_d)\n",
    "\n",
    "reg_departure.fit(X_train_d, y_train_d,\n",
    "                  eval_set=[(X_val_d, y_val_d)],\n",
    "                  eval_metric='l2',\n",
    "                  early_stopping_rounds = 10, \n",
    "                  verbose = False)     # loss fuction이 n번 이상 좋아지지 않으면 멈춰라"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe582042",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2be771",
   "metadata": {},
   "source": [
    "for loop안에서 predict하고 평균을 내야 함 <br>\n",
    "-> demand를 하나씩 증가시키리면, 바로 CV를 사용하기는 어려울 듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a3c1a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T07:45:04.461686Z",
     "start_time": "2021-07-08T07:44:58.334Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "n_fold = 10\n",
    "\n",
    "cv = KFold(n_splits=n_fold, shuffle=True, random_state=seed)\n",
    "\n",
    "p_val_a = np.zeros(X_a.shape[0])\n",
    "predict_a = np.zeros(X_a.shape[0])\n",
    "p_val_d = np.zeros(X_d.shape[0])\n",
    "predict_d = np.zeros(X_d.shape[0])\n",
    "\n",
    "############### 위에서 X_val_a등으로 바꾼 거 없애고 -> 아래 X_a, y_a, X_d, y_d를 X_train_a 등으로 바꾸기 #######################\n",
    "\n",
    "for i, (i_trn, i_val) in enumerate(cv.split(X_a, y_a), 1):        # 몇번째인지 보기 위해 enumerate 사용\n",
    "    print('----------------------------------------------------------------------------')\n",
    "    print(f'Training model for Cross-Validation #{i}')\n",
    "    reg_arrival = LGBMRegressor(**params)    #############params_a\n",
    "    reg_arrival.fit(X_a[i_trn], y_a[i_trn],\n",
    "                sample_weight = None,                   # Weights of training data\n",
    "                init_score = None,                      # Weights of training data\n",
    "                eval_set = [(X_a[i_val], y_a[i_val])],  # pairs to use as validation sets\n",
    "                eval_sample_weight = None,              # Weights of eval data\n",
    "                eval_init_score = None,                 # Init score of eval data.   \n",
    "                eval_metric = 'l2',                     # Default: ‘l2’ for LGBMRegressor, ‘logloss’ for LGBMClassifier, ‘ndcg’ for LGBMRanker\n",
    "                early_stopping_rounds = 10 )            # loss fuction이 n번 이상 좋아지지 않으면 멈춰라\n",
    "    \n",
    "    p_val_a[i_val] = reg_arrival.predict(X_a[i_val])\n",
    "    predict_a += reg_arrival.predict(X_a) / n_fold      ##### 이 자리에 원래는 test data가 들어가면 됨\n",
    "                                                        # test data의 prediction은 CV에서 각 dataset이 예측한 값들의 평균이므로\n",
    "    \n",
    "for i, (i_trn, i_val) in enumerate(cv.split(X_d, y_d), 1):        # 몇번째인지 보기 위해 enumerate 사용\n",
    "    print('----------------------------------------------------------------------------')\n",
    "    print(f'Training model for Cross-Validation #{i}')\n",
    "    reg_departure = LGBMRegressor(**params)    #############params_d\n",
    "    reg_departure.fit(X_d[i_trn], y_d[i_trn],\n",
    "                      sample_weight = None,                   # Weights of training data\n",
    "                      init_score = None,                      # Weights of training data\n",
    "                      eval_set = [(X_d[i_val], y_d[i_val])],  # pairs to use as validation sets\n",
    "                      eval_sample_weight = None,              # Weights of eval data\n",
    "                      eval_init_score = None,                 # Init score of eval data.   \n",
    "                      eval_metric = 'l2',                     # Default: ‘l2’ for LGBMRegressor, ‘logloss’ for LGBMClassifier, ‘ndcg’ for LGBMRanker\n",
    "                      early_stopping_rounds = 10 )            # loss fuction이 n번 이상 좋아지지 않으면 멈춰라\n",
    "    \n",
    "    p_val_d[i_val] = reg_departure.predict(X_d[i_val])\n",
    "    predict_d += reg_departure.predict(X_d) / n_fold          ##### 이 자리에 원래는 test data가 들어가면 됨\n",
    "                                                              # test data의 prediction은 CV에서 각 dataset이 예측한 값들의 평균이므로\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39b4cd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T07:45:04.462687Z",
     "start_time": "2021-07-08T07:44:58.336Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print(f'Arrival RMSE : {np.sqrt(mean_squared_error(y_a, predict_a)):.4f}')\n",
    "print(f'Arrival Training R^2 : {r2_score(y_a, predict_a) * 100:.4f}')\n",
    "print(f'Departure RMSE : {np.sqrt(mean_squared_error(y_d, predict_d)):.4f}')\n",
    "print(f'Departure Training R^2 : {r2_score(y_d, predict_d) * 100:.4f}')\n",
    "\n",
    "np.savetxt('p_val_a.csv', p_val_a, fmt='%.6f', delimiter=',')\n",
    "np.savetxt('p_val_d.csv', p_val_d, fmt='%.6f', delimiter=',')\n",
    "np.savetxt('predict_a.csv', predict_a, fmt='%.6f', delimiter=',')\n",
    "np.savetxt('predict_d.csv', predict_d, fmt='%.6f', delimiter=',')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000b2b98",
   "metadata": {},
   "source": [
    "이렇게 각각의 model의(e.g. lightGBM, XGBOOST, Randomforest ...) Cross Validation을 예측한 결과와, Test data에 대해 예측한 결과를 파일로 저장 <br>\n",
    "-> 다음 stage에서는 CV결과들을 input data로 사용, 기존의 label은 그대로 사용, test data의 예측값을 다음 stage에서 test data의 input으로 사용 <br>\n",
    "-> 계속 쌓아갈 수 있음 (=Stacking, 보통 stage 1,2정도면 이후 효과는 미비)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b836ae0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-05T11:49:38.039928Z",
     "start_time": "2021-07-05T11:49:38.022938Z"
    }
   },
   "source": [
    "stacking, ensemble 보다 feature engineering, hyperparameter tuning의 성능 향상이 훨씬 커서 앞의 방법은 굳이 사용하지 않아도 괜찮음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaeb0825",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd992057",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5e319a",
   "metadata": {},
   "source": [
    "<sklearn.metrics> <br>\n",
    "\n",
    "* regression <br>\n",
    "mean_squared_error, mean_absolute_error, r2_score <br><br>\n",
    "\n",
    "* classification <br>\n",
    "log_loss, roc_auc_score, accuracy_score, confusion_matrix <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa2bfe6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-24T06:02:52.505806Z",
     "start_time": "2021-07-24T06:02:52.490810Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def Test(Data_raw, ops='arrival', start=0, end = 10):        # ops : arrival , departure\n",
    "    if ops == 'arrival':\n",
    "        Data_raw = Data_raw.drop('ADR', axis=1)\n",
    "        datelist = pd.DataFrame(pd.date_range('2019-01-01', '2019-12-31 23:00', freq = '1h'))\n",
    "        test_result = pd.DataFrame({'Date' : datelist[start:end][0],\n",
    "                                    'EAD' : Data_raw['EAD'][start:end],\n",
    "                                    'Actual AAR' : Data_raw['AAR'][start:end], \n",
    "                                    'Predicted AAR' : reg_arrival.predict(Data_raw.drop('AAR', axis=1)[start:end]), \n",
    "                                    'Difference' : reg_arrival.predict(Data_raw.drop('AAR', axis=1)[start:end]) - Data_raw['AAR'][start:end]})\n",
    "    elif ops == 'departure':\n",
    "        Data_raw = Data_raw.drop('AAR', axis=1)        \n",
    "        datelist = pd.DataFrame(pd.date_range('2019-01-01', '2019-12-31 23:00', freq = '1h'))\n",
    "        test_result = pd.DataFrame({'Date' : datelist[start:end][0],\n",
    "                                    'EDD' : Data_raw['EDD'][start:end],\n",
    "                                    'Actual ADR' : Data_raw['ADR'][start:end], \n",
    "                                    'Predicted ADR' : reg_departure.predict(Data_raw.drop('ADR', axis=1)[start:end]), \n",
    "                                    'Difference' : reg_departure.predict(Data_raw.drop('ADR', axis=1)[start:end]) - Data_raw['ADR'][start:end]})\n",
    "        \n",
    "    return test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2d00c3",
   "metadata": {},
   "source": [
    "***\n",
    "## Arrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc199b2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-24T06:02:59.877139Z",
     "start_time": "2021-07-24T06:02:53.707817Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict & Evaluation\n",
    "\n",
    "y_hat_a = reg_arrival.predict(X_a)\n",
    "print(f'Total RMSE : {np.sqrt(mean_squared_error(y_a, y_hat_a)):.4f}')\n",
    "\n",
    "print(f'Training R^2 : {r2_score(y_train_a, reg_arrival.predict(X_train_a)) :.4f}')\n",
    "print(f'Test R^2 : {r2_score(y_test_a, reg_arrival.predict(X_test_a)) :.4f}')\n",
    "\n",
    "print(f'Training RMSE : {np.sqrt(mean_squared_error(y_train_a, reg_arrival.predict(X_train_a))):.4f}')\n",
    "print(f'Test RMSE : {np.sqrt(mean_squared_error(y_test_a, reg_arrival.predict(X_test_a))):.4f}')\n",
    "#print(f'explained variance score : {explained_variance_score(y_a, y_hat_a) :.4f}')\n",
    "#print(f'max error : {max_error(y_a, y_hat_a) :.4f}')\n",
    "#print(f'mean absolute error : {mean_absolute_error(y_a, y_hat_a) :.4f}')\n",
    "#print(f'mean absolute percentage error : {mean_absolute_percentage_error(y_a, y_hat_a)}')\n",
    "#print(f'mean squared log error : {mean_squared_log_error(y_a, y_hat_a) :.4f}')\n",
    "#print(f'median absolute error : {median_absolute_error(y_a, y_hat_a) :.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940488ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-24T06:03:01.501719Z",
     "start_time": "2021-07-24T06:03:00.962140Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "imp = pd.DataFrame({'feature': Data_m.columns, 'importance': reg_arrival.feature_importances_})\n",
    "imp = imp.sort_values('importance').set_index('feature')\n",
    "imp.plot(kind='barh', figsize = (20,20))\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a980fc7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-24T06:03:02.688047Z",
     "start_time": "2021-07-24T06:03:02.533705Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_metric(reg_arrival, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dfaa6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-24T06:03:06.922772Z",
     "start_time": "2021-07-24T06:03:03.779644Z"
    }
   },
   "outputs": [],
   "source": [
    "# AAR - pred\n",
    "pred_test_a = Data_raw.drop('ADR', axis=1)\n",
    "pred_test_a['pred_a'] = reg_arrival.predict(pred_test_a.drop('AAR', axis=1))\n",
    "sns.pairplot(data=pred_test_a, vars=['AAR','pred_a'], size=10, plot_kws={'alpha': .5}, kind ='scatter' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c3f8a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-24T06:03:13.350566Z",
     "start_time": "2021-07-24T06:03:08.447716Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "Test_all = Test(Data_raw, ops='arrival', start = 0, end = 8760).sort_values('Difference')\n",
    "Test_all['Difference'].abs().sort_values(ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ab7e5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-24T06:03:20.482848Z",
     "start_time": "2021-07-24T06:03:14.836279Z"
    }
   },
   "outputs": [],
   "source": [
    "Test(Data_raw, ops='arrival', start = 0, end = 8760)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fd6528",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T06:13:25.606464Z",
     "start_time": "2021-07-02T06:13:25.593482Z"
    }
   },
   "source": [
    "-------------------\n",
    "## Departure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30080786",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-24T06:05:02.108397Z",
     "start_time": "2021-07-24T06:04:55.963982Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict & Evaluation\n",
    "print(f'Total RMSE : {np.sqrt(mean_squared_error(y_d, reg_departure.predict(X_d))):.4f}')\n",
    "\n",
    "print(f'Training R^2 : {r2_score(y_train_d, reg_departure.predict(X_train_d)) :.4f}')\n",
    "print(f'Test R^2 : {r2_score(y_test_d, reg_departure.predict(X_test_d)) :.4f}')\n",
    "\n",
    "print(f'Training RMSE : {np.sqrt(mean_squared_error(y_train_d, reg_departure.predict(X_train_d))):.4f}')\n",
    "print(f'Test RMSE : {np.sqrt(mean_squared_error(y_test_d, reg_departure.predict(X_test_d))):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c61338",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-24T06:05:03.786903Z",
     "start_time": "2021-07-24T06:05:03.363903Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "imp = pd.DataFrame({'feature': Data_m.columns, 'importance': reg_departure.feature_importances_})\n",
    "imp = imp.sort_values('importance').set_index('feature')\n",
    "imp.plot(kind='barh', figsize = (20,20))\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e0c494",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-24T06:05:05.304674Z",
     "start_time": "2021-07-24T06:05:05.129672Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_metric(reg_departure, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba27e7b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-24T06:05:09.845017Z",
     "start_time": "2021-07-24T06:05:06.589677Z"
    }
   },
   "outputs": [],
   "source": [
    "# ADR - pred\n",
    "pred_test_d = Data_raw.drop('AAR', axis=1)\n",
    "pred_test_d['Prediction_departure'] = reg_departure.predict(pred_test_d.drop('ADR', axis=1))\n",
    "sns.pairplot(data=pred_test_d, vars=['ADR','Prediction_departure'], size=10, plot_kws={'alpha': .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523608f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-24T06:05:11.868685Z",
     "start_time": "2021-07-24T06:05:11.474278Z"
    }
   },
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "#############################################################################################################\n",
    "#############################################################################################################\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "\n",
    "sns.scatterplot(data = pred_test_d, x = \"ADR\", y = \"Prediction_departure\" , ax = ax1)\n",
    "sns.distplot(pred_test_d[\"ADR\"], label = 'ADR', kde = False, ax = ax2)\n",
    "sns.distplot(pred_test_d[\"Prediction_departure\"], label = 'Prediction', kde = False, ax = ax2)\n",
    "\n",
    "ax1.set(xlabel='Actual Departure Rate', ylabel='Departure Prediction')\n",
    "ax2.set(xlabel='Departures per hour', ylabel='Count')\n",
    "#ax1.set_title('aaa')\n",
    "#ax2.set_title('bbb')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#############################################################################################################\n",
    "#############################################################################################################\n",
    "#############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9ebe47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T14:32:50.154177Z",
     "start_time": "2021-07-19T14:32:45.332147Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "Test_all = Test(Data_raw, ops='departure', start = 0, end = 8760).sort_values('Difference')\n",
    "Test_all['Difference'].abs().sort_values(ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bc6a8f",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b213caa7",
   "metadata": {},
   "source": [
    "# Maximum Capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76463f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T09:06:29.842234Z",
     "start_time": "2021-07-09T09:06:29.822137Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "# 예전 버전 : 원래 demand부터 시작 -> extra demand를 더함\n",
    "\n",
    "def max_capacity(Data_raw, Data_m, example):   \n",
    "    \n",
    "    # extra\n",
    "    extra_demand = 50\n",
    "    \n",
    "    # arrival\n",
    "    data_a = Data_m.to_numpy()[example:example+1]\n",
    "    XX_a = np.zeros((1,len(data_a.T)))\n",
    "    for i in range(extra_demand+1):\n",
    "        XX_a = np.append(XX_a, data_a, axis = 0)\n",
    "        XX_a[i,0] = XX_a[i,0] + i-1\n",
    "    XXX_a = XX_a[1:extra_demand+1]\n",
    "    XXXX_a = np.arange(XXX_a[0,0], XXX_a[extra_demand-1,0]+1, 1)\n",
    "    YYYY_a = reg_arrival.predict(XXX_a[0:extra_demand+1])\n",
    "    max_aar = float(max(YYYY_a))\n",
    "    actual_aar = int(Data_raw['AAR'][example:example+1])\n",
    "    ead = int(Data_raw['EAD'][example:example+1])\n",
    "    prediction_a = float(reg_arrival.predict(Data_m[example:example+1]))\n",
    "    \n",
    "    # departure\n",
    "    data_d = Data_m.to_numpy()[example:example+1]\n",
    "    XX_d = np.zeros((1,len(data_d.T)))\n",
    "    for i in range(extra_demand+1):\n",
    "        XX_d = np.append(XX_d, data_d, axis = 0)\n",
    "        XX_d[i,2] = XX_d[i,2] + i-1\n",
    "    XXX_d = XX_d[1:extra_demand+1]\n",
    "    XXXX_d = np.arange(XXX_d[0,2], XXX_d[extra_demand-1,2]+1, 1)\n",
    "    YYYY_d = reg_departure.predict(XXX_d[0:extra_demand+1])\n",
    "    max_adr = float(max(YYYY_d))\n",
    "    actual_adr = int(Data_raw['ADR'][example:example+1])\n",
    "    edd = int(Data_raw['EDD'][example:example+1])\n",
    "    prediction_d = float(reg_departure.predict(Data_m[example:example+1])) \n",
    "\n",
    "    # Total\n",
    "    result_ = pd.DataFrame({'EAD' : XXXX_a ,'Predicted AAR' : YYYY_a, 'EDD' : XXXX_d ,'Predicted ADR' : YYYY_d, \n",
    "                            'Demand' : XXXX_a + YYYY_a, 'Capacity' : YYYY_a + YYYY_d})\n",
    "    \n",
    "    # plot\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.title('Maximum Capacity', fontsize=30)\n",
    "    plt.xlabel('Estimated Demands', fontsize=25)\n",
    "    plt.ylabel('Capacity', fontsize=25)\n",
    "    plt.plot(XXXX_a, YYYY_a, label = 'Arrival')\n",
    "    plt.plot(XXXX_d, YYYY_d, label = 'Departure')\n",
    "    plt.plot(XXXX_a[:-15]+XXXX_d[:-15], YYYY_a[:-15] + YYYY_d[:-15], label = 'Total')   # 안 예뻐서 뒤에 15개 자름\n",
    "    plt.legend(prop={'size': 20})\n",
    "    ax = plt.subplot()\n",
    "    plt.text(0.95, 0.04,    # 위치조정\n",
    "             f\"\"\"\n",
    "             * Predicted Max AAR: {max_aar:.3f}\\n\n",
    "               Predicted AAR : {prediction_a:.3f}\\n\n",
    "               Actual AAR : {actual_aar} \\n               \n",
    "               EAD : {ead} \\n\\n\n",
    "             \n",
    "             * Predicted Max ADR: {max_adr:.3f}\\n\n",
    "               Predicted ADR : {prediction_d:.3f}\\n\n",
    "               Actual ADR : {actual_adr} \\n               \n",
    "               EDD : {edd} \\n\\n\n",
    "             \n",
    "             * Predicted Max Capacity: {max_aar + max_adr:.3f}\\n\n",
    "               Predicted Rate : {prediction_a + prediction_d:.3f}\\n\n",
    "               Actual Rate : {actual_aar + actual_adr} \\n               \n",
    "               Demand : {ead + edd}'\n",
    "             \"\"\",\n",
    "             fontsize=15, style='italic', transform=ax.transAxes, bbox={'facecolor': 'grey', 'alpha': 0, 'pad': 5})\n",
    "    plt.show()    \n",
    "    return result_\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2941c682",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-20T12:32:18.221095Z",
     "start_time": "2021-07-20T12:32:18.190090Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# *** training data에는 AAR, ADR 둘다 없어야 함\n",
    "# 0부터 시작\n",
    "# max capacity 선 추가\n",
    "# 원래 demand에 대한 predict 점 추가\n",
    "\n",
    "def max_capacity(Data_raw, Data_m, example):    # 50까지 늘림\n",
    "    \n",
    "    # extra\n",
    "    demand = 80\n",
    "    \n",
    "\n",
    "    # arrival\n",
    "    data_a = Data_m.to_numpy()[example:example+1]\n",
    "    XX_a = np.zeros((1,len(data_a.T)))\n",
    "    \n",
    "    original_demand_a = int(data_a[0][0])\n",
    "    for i in range(0,demand+1):\n",
    "        XX_a = np.append(XX_a, data_a, axis = 0)\n",
    "        XX_a[i,0] = XX_a[i,0] + i - original_demand_a\n",
    "    \n",
    "    XX_a[0] = XX_a[1]   \n",
    "    XX_a[0,0] = 0   \n",
    "    XXX_a = XX_a[0:demand+1]\n",
    "    XXXX_a = np.arange(XXX_a[0,0], XXX_a[demand,0]+1, 1)\n",
    "    YYYY_a = reg_arrival.predict(XXX_a[0:demand+1])\n",
    "    max_aar = float(max(YYYY_a))\n",
    "    actual_aar = int(Data_raw.drop('ADR', axis=1)['AAR'][example:example+1])\n",
    "    ead = int(Data_raw.drop('ADR', axis=1)['EAD'][example:example+1])\n",
    "    prediction_a = float(reg_arrival.predict(Data_m[example:example+1]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # departure\n",
    "    data_d = Data_m.to_numpy()[example:example+1]\n",
    "    XX_d = np.zeros((1,len(data_d.T)))\n",
    "    \n",
    "    original_demand_d = int(data_d[0][1])\n",
    "    for i in range(0,demand+1):\n",
    "        XX_d = np.append(XX_d, data_d, axis = 0)\n",
    "        XX_d[i,1] = XX_d[i,1] + i - original_demand_d\n",
    "        \n",
    "    XX_d[0] = XX_d[1]           \n",
    "    XX_d[0,1] = 0\n",
    "    XXX_d = XX_d[0:demand+1]\n",
    "    XXXX_d = np.arange(XXX_d[0,1], XXX_d[demand,1]+1, 1)\n",
    "    YYYY_d = reg_departure.predict(XXX_d[0:demand+1])\n",
    "    max_adr = float(max(YYYY_d))\n",
    "    actual_adr = int(Data_raw.drop('AAR', axis=1)['ADR'][example:example+1])\n",
    "    edd = int(Data_raw.drop('AAR', axis=1)['EDD'][example:example+1])\n",
    "    prediction_d = float(reg_departure.predict(Data_m[example:example+1])) \n",
    "\n",
    "    \n",
    "    \n",
    "    # capacity - arrival과 departure을 수요의 비율로 늘렸을 때\n",
    "    max_cap = int(max(Data_raw['AAR'] + Data_raw['ADR']))\n",
    "    max_capacity = np.zeros(demand+1)\n",
    "    for i in range(0,demand*2+1,2):\n",
    "        if round(i*data_a[0,0]/(data_a[0,0]+data_d[0,1])) >=75:\n",
    "            capa_arr = YYYY_a[75]\n",
    "        elif round(i*data_d[0,1]/(data_a[0,0]+data_d[0,1])) >=75:\n",
    "            capa_dep = YYYY_d[75]\n",
    "        else:\n",
    "            capa_arr = YYYY_a[round(i*data_a[0,0]/(data_a[0,0]+data_d[0,1]))]\n",
    "            capa_dep = YYYY_d[round(i*data_d[0,1]/(data_a[0,0]+data_d[0,1]))]\n",
    "        max_capacity[int(i/2)] = capa_arr + capa_dep\n",
    "    \n",
    "    \n",
    "    \n",
    "    # plot\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.title('Maximum Capacity', fontsize=30)\n",
    "    plt.xlabel('Estimated Demands', fontsize=25)\n",
    "    plt.ylabel('Capacity', fontsize=25)\n",
    "    ax = plt.subplot()\n",
    "\n",
    "    plt.plot(XXXX_a, YYYY_a, label = 'Arrival')    # Arrival\n",
    "    plt.plot(XXXX_d, YYYY_d, label = 'Departure')    # Departure\n",
    "    plt.plot(XXXX_a[:-5] + XXXX_d[:-5], max_capacity[:-5], label = 'Total')    # Capacity - 안 예뻐서 뒤에 55개 자름\n",
    "    plt.plot(XXXX_a[:-5]+XXXX_d[:-5], [max_cap]*(demand-4), label = f'Empirical Maximum = {max_cap}')    # 데이터 상 max capacity\n",
    "    \n",
    "    plt.plot(data_a[0,0], prediction_a,'ob', markersize = 10)    # 원래 arrival 예측값\n",
    "    plt.plot(data_d[0,1], prediction_d,'or', markersize = 10)    # 원래 departure 예측값\n",
    "    plt.plot(data_a[0,0]+data_d[0,1], prediction_a + prediction_d,'yo', markersize = 15)    # 원래 capacity 예측값\n",
    "    plt.legend(prop={'size': 20}, loc = 'upper left')\n",
    "\n",
    "    plt.text(0.95, 0.04,    # 위치조정\n",
    "             f\"\"\"\n",
    "             * Predicted Max AAR: {max_aar:.1f}\\n\n",
    "               Predicted AAR : {prediction_a:.1f}\\n\n",
    "               Actual AAR : {actual_aar} \\n               \n",
    "               EAD : {ead} \\n\\n\n",
    "             \n",
    "             * Predicted Max ADR: {max_adr:.1f}\\n\n",
    "               Predicted ADR : {prediction_d:.1f}\\n\n",
    "               Actual ADR : {actual_adr} \\n               \n",
    "               EDD : {edd} \\n\\n\n",
    "             \n",
    "             * Predicted Max Capacity: {max_aar + max_adr:.1f}\\n\n",
    "               Predicted Rate : {prediction_a + prediction_d:.1f}\\n\n",
    "               Actual Rate : {actual_aar + actual_adr} \\n               \n",
    "               Demand : {ead + edd}'\n",
    "             \"\"\",\n",
    "             fontsize=15, style='italic', transform=ax.transAxes, bbox={'facecolor': 'grey', 'alpha': 0, 'pad': 5})\n",
    "    \n",
    "    plt.show()   \n",
    "    \n",
    "    return Data_raw[example:example+1]   #result_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84eaa5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-20T12:32:20.081982Z",
     "start_time": "2021-07-20T12:32:19.582746Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 원하는 시간의 Max Capacity 그래프\n",
    "\n",
    "max_capacity(Data_raw, Data_m, 154)     # 숫자에 원하는 Data index(0-8760) 넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc5c976",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-25T12:22:59.559179Z",
     "start_time": "2021-07-25T12:22:59.548032Z"
    }
   },
   "outputs": [],
   "source": [
    "np.ones((5,3))[:,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30ed1ea",
   "metadata": {},
   "source": [
    "< Notable Samples> \n",
    "\n",
    "* pd.DataFrame(Data_raw).idxmax()             # 각 column별 max값의 index\n",
    "\n",
    "AAR 최소 : 2 <br>\n",
    "AAR 최대 : 1481 <br>\n",
    "EAD 최대 : 641 <br>\n",
    "ADR 최소 : 28 <br>\n",
    "ADR 최대 : 538 <br>\n",
    "EDD 최대 : 273 <br>\n",
    "Total Rate(AAR+ADR) 최대(77) : 5703 <br>\n",
    "Total Demand(EAD+EDD) 최대(70) : 4814 <br><br>\n",
    "\n",
    "Arrival_reaminder 최대 : 5992 <br>\n",
    "Departure_remainder 최대 : 8242 <br><br>\n",
    "\n",
    "WSPD 최대 : 5990 <br>\n",
    "W_GST 최대 : 5990 <br>\n",
    "시정 최소 : 1755 <br>\n",
    "Ceiling 최소 : 321 <br>\n",
    "RVR 최소 1448 <br><br>\n",
    "\n",
    "TAF WSPD 최대 : 5988 <br>\n",
    "TAF W_GST 최대 : 5988 <br>\n",
    "TAF 시정 최소 : 319 <br>\n",
    "TAF Ceiling 최소 : 10?? <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a3b7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data : 불러온 파일\n",
    "# Data_temp : 일단 필요 없어 보이는 column을 버린 것\n",
    "# data_taf : dictinoary 안에 Data_6 - Data_24 전부 넣은 것\n",
    "# Data_6, Data_12 .. : 해당 시간 전의 TAF만 있고, 나머지 시간의 TAF는 버린 것\n",
    "# Data_raw : Data_#과 동일\n",
    "# Data_m : Data_# 에서 AAR, ADR 뺀 것\n",
    "# Data_a : Data_m 로 바꿈\n",
    "# Data_d : Data_m 로 바꿈"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e38ac3",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaedeb85",
   "metadata": {},
   "source": [
    "# 추가 실험"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3800d3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T13:21:03.884649Z",
     "start_time": "2021-07-07T13:21:03.869492Z"
    }
   },
   "source": [
    "##  왜 AAR에서 중간이 비는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55fa079",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T05:50:20.567568Z",
     "start_time": "2021-07-14T05:50:17.513152Z"
    }
   },
   "outputs": [],
   "source": [
    "a = reg_arrival.predict(X_a)\n",
    "np.rint(a)        # 반올림하고 정수로 만듦\n",
    "pd.DataFrame(np.rint(a)).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbce337c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T05:50:48.972318Z",
     "start_time": "2021-07-14T05:50:48.959318Z"
    }
   },
   "outputs": [],
   "source": [
    "# AAR수 별로 정렬\n",
    "Data['AAR'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bd2a38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T05:53:40.039579Z",
     "start_time": "2021-07-14T05:53:39.908445Z"
    }
   },
   "outputs": [],
   "source": [
    "# 12에서 16으로 예측한 날들 표시\n",
    "pred = pd.DataFrame({'pred' :reg_arrival.predict(Data_m)})\n",
    "pred_low = pred[(pred['pred'] < 16) & (pred['pred'] >= 12)].index\n",
    "Data.loc[pred_low]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ca7316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f34a06c1",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69096e6e",
   "metadata": {},
   "source": [
    "# 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e641ec29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T10:28:03.089056Z",
     "start_time": "2021-07-08T10:27:59.572912Z"
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "lgbr_a = \"../evaluate/lgbr_a.pkl\"\n",
    "lgbr_d = \"../evaluate/lgbr_d.pkl\"\n",
    "joblib.dump(reg_arrival, lgbr_a)\n",
    "joblib.dump(reg_departure, lgbr_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4962b27d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T07:42:56.404102Z",
     "start_time": "2021-07-27T07:42:56.384481Z"
    }
   },
   "outputs": [],
   "source": [
    "# extra\n",
    "demand = 80\n",
    "example = 10\n",
    "\n",
    "# arrival\n",
    "data_a = Data_m.to_numpy()[example:example+1]\n",
    "XX_a = np.zeros((1,len(data_a.T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eb3e7be0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T08:00:02.140993Z",
     "start_time": "2021-07-27T08:00:02.136992Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data_m = data_arrival\n",
    "date = Data_m[example:example+1]\n",
    "date = datetime.datetime(date['year'][example], date['month'][example], date['day'][example], date['hour'][example])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80ac1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_demand_a = int(data_a[0][0])\n",
    "for i in range(0,demand+1):\n",
    "    XX_a = np.append(XX_a, data_a, axis = 0)\n",
    "    XX_a[i,0] = XX_a[i,0] + i - original_demand_a\n",
    "\n",
    "XX_a[0] = XX_a[1]   \n",
    "XX_a[0,0] = 0   \n",
    "XXX_a = XX_a[0:demand+1]\n",
    "XXXX_a = np.arange(XXX_a[0,0], XXX_a[demand,0]+1, 1)\n",
    "YYYY_a = reg_arrival.predict(XXX_a[0:demand+1])\n",
    "max_aar = float(max(YYYY_a))\n",
    "actual_aar = int(Data_raw.drop('ADR', axis=1)['AAR'][example:example+1])\n",
    "ead = int(Data_raw.drop('ADR', axis=1)['EAD'][example:example+1])\n",
    "prediction_a = float(reg_arrival.predict(Data_m[example:example+1]))\n",
    "\n",
    "\n",
    "\n",
    "# departure\n",
    "data_d = Data_m.to_numpy()[example:example+1]\n",
    "XX_d = np.zeros((1,len(data_d.T)))\n",
    "\n",
    "original_demand_d = int(data_d[0][1])\n",
    "for i in range(0,demand+1):\n",
    "    XX_d = np.append(XX_d, data_d, axis = 0)\n",
    "    XX_d[i,1] = XX_d[i,1] + i - original_demand_d\n",
    "\n",
    "XX_d[0] = XX_d[1]           \n",
    "XX_d[0,1] = 0\n",
    "XXX_d = XX_d[0:demand+1]\n",
    "XXXX_d = np.arange(XXX_d[0,1], XXX_d[demand,1]+1, 1)\n",
    "YYYY_d = reg_departure.predict(XXX_d[0:demand+1])\n",
    "max_adr = float(max(YYYY_d))\n",
    "actual_adr = int(Data_raw.drop('AAR', axis=1)['ADR'][example:example+1])\n",
    "edd = int(Data_raw.drop('AAR', axis=1)['EDD'][example:example+1])\n",
    "prediction_d = float(reg_departure.predict(Data_m[example:example+1])) \n",
    "\n",
    "\n",
    "\n",
    "# capacity - arrival과 departure을 수요의 비율로 늘렸을 때\n",
    "max_cap = int(max(Data_raw['AAR'] + Data_raw['ADR']))\n",
    "max_capacity = np.zeros(demand+1)\n",
    "for i in range(0,demand*2+1,2):\n",
    "    if round(i*data_a[0,0]/(data_a[0,0]+data_d[0,1])) >=75:\n",
    "        capa_arr = YYYY_a[75]\n",
    "    elif round(i*data_d[0,1]/(data_a[0,0]+data_d[0,1])) >=75:\n",
    "        capa_dep = YYYY_d[75]\n",
    "    else:\n",
    "        capa_arr = YYYY_a[round(i*data_a[0,0]/(data_a[0,0]+data_d[0,1]))]\n",
    "        capa_dep = YYYY_d[round(i*data_d[0,1]/(data_a[0,0]+data_d[0,1]))]\n",
    "    max_capacity[int(i/2)] = capa_arr + capa_dep\n",
    "\n",
    "\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.title('Maximum Capacity', fontsize=30)\n",
    "plt.xlabel('Estimated Demands', fontsize=25)\n",
    "plt.ylabel('Capacity', fontsize=25)\n",
    "ax = plt.subplot()\n",
    "\n",
    "plt.plot(XXXX_a, YYYY_a, label = 'Arrival')    # Arrival\n",
    "plt.plot(XXXX_d, YYYY_d, label = 'Departure')    # Departure\n",
    "plt.plot(XXXX_a[:-5] + XXXX_d[:-5], max_capacity[:-5], label = 'Total')    # Capacity - 안 예뻐서 뒤에 55개 자름\n",
    "plt.plot(XXXX_a[:-5]+XXXX_d[:-5], [max_cap]*(demand-4), label = f'Empirical Maximum = {max_cap}')    # 데이터 상 max capacity\n",
    "\n",
    "plt.plot(data_a[0,0], prediction_a,'ob', markersize = 10)    # 원래 arrival 예측값\n",
    "plt.plot(data_d[0,1], prediction_d,'or', markersize = 10)    # 원래 departure 예측값\n",
    "plt.plot(data_a[0,0]+data_d[0,1], prediction_a + prediction_d,'yo', markersize = 15)    # 원래 capacity 예측값\n",
    "plt.legend(prop={'size': 20}, loc = 'upper left')\n",
    "\n",
    "plt.text(0.95, 0.04,    # 위치조정\n",
    "         f\"\"\"\n",
    "         * Predicted Max AAR: {max_aar:.1f}\\n\n",
    "           Predicted AAR : {prediction_a:.1f}\\n\n",
    "           Actual AAR : {actual_aar} \\n               \n",
    "           EAD : {ead} \\n\\n\n",
    "\n",
    "         * Predicted Max ADR: {max_adr:.1f}\\n\n",
    "           Predicted ADR : {prediction_d:.1f}\\n\n",
    "           Actual ADR : {actual_adr} \\n               \n",
    "           EDD : {edd} \\n\\n\n",
    "\n",
    "         * Predicted Max Capacity: {max_aar + max_adr:.1f}\\n\n",
    "           Predicted Rate : {prediction_a + prediction_d:.1f}\\n\n",
    "           Actual Rate : {actual_aar + actual_adr} \\n               \n",
    "           Demand : {ead + edd}'\n",
    "         \"\"\",\n",
    "         fontsize=15, style='italic', transform=ax.transAxes, bbox={'facecolor': 'grey', 'alpha': 0, 'pad': 5})\n",
    "\n",
    "plt.show()   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "262px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "503px",
    "left": "1550px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
