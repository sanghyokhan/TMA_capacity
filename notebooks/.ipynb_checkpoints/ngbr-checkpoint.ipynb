{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ca3c213",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T08:35:48.438029Z",
     "start_time": "2021-07-27T08:35:41.999115Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from ngboost import NGBRegressor\n",
    "from ngboost.distns import Normal\n",
    "from ngboost.scores import CRPScore, MLE\n",
    "from ngboost.ngboost import NGBoost\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from hyperopt import hp, tpe, space_eval\n",
    "from hyperopt.pyll.base import scope\n",
    "from hyperopt.fmin import fmin\n",
    "from hyperopt import STATUS_OK, Trials\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab1c6a7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T08:35:49.251495Z",
     "start_time": "2021-07-27T08:35:49.233502Z"
    }
   },
   "outputs": [],
   "source": [
    "# options\n",
    "pd.set_option('max_columns',100)\n",
    "plt.style.use('fivethirtyeight')\n",
    "warnings.simplefilter('ignore')\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93f11730",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T08:35:49.799663Z",
     "start_time": "2021-07-27T08:35:49.789669Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data dirctory\n",
    "data_dir = Path('../data/')\n",
    "data_file = data_dir / 'data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4917a61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T08:35:51.180724Z",
     "start_time": "2021-07-27T08:35:50.917879Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "# 0:AAR / 1:EAD / 2:ADR / 3:EDD는 고정  , 나머지는 순서 상관 없음\n",
    "Data = pd.read_csv(data_file, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef731297",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67171ae7",
   "metadata": {},
   "source": [
    "# Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d675da2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T08:35:53.892329Z",
     "start_time": "2021-07-27T08:35:53.560834Z"
    }
   },
   "outputs": [],
   "source": [
    "# 필요없는 것을 버리기\n",
    "Data_temp = Data.drop('TMP', axis=1)\n",
    "Data_temp = Data_temp.drop('TD', axis=1)\n",
    "Data_temp = Data_temp.drop('HM', axis=1)\n",
    "Data_temp = Data_temp.drop('PS', axis=1)\n",
    "Data_temp = Data_temp.drop('PA', axis=1)\n",
    "\n",
    "#고층바람 너무 높은 고도는 뺴자 \n",
    "Data_temp = Data_temp.drop('WD_400', axis=1)\n",
    "Data_temp = Data_temp.drop('WD_500', axis=1)\n",
    "Data_temp = Data_temp.drop('WD_700', axis=1)\n",
    "Data_temp = Data_temp.drop('WS_400', axis=1)\n",
    "Data_temp = Data_temp.drop('WS_500', axis=1)\n",
    "Data_temp = Data_temp.drop('WS_700', axis=1)\n",
    "\n",
    "# drop TAF\n",
    "for i in range(6,30,6):\n",
    "    Data_temp = Data_temp.drop(f'WDIR_t{i}', axis=1)\n",
    "    Data_temp = Data_temp.drop(f'WSPD_t{i}', axis=1)\n",
    "    Data_temp = Data_temp.drop(f'WG_t{i}', axis=1)\n",
    "    Data_temp = Data_temp.drop(f'VIS_t{i}', axis=1)\n",
    "    Data_temp = Data_temp.drop(f'WC_t{i}', axis=1)\n",
    "    Data_temp = Data_temp.drop(f'CLA_1LYR_t{i}', axis=1)\n",
    "    Data_temp = Data_temp.drop(f'BASE_1LYR_t{i}', axis=1)\n",
    "    Data_temp = Data_temp.drop(f'CLA_2LYR_t{i}', axis=1)\n",
    "    Data_temp = Data_temp.drop(f'BASE_2LYR_t{i}', axis=1)\n",
    "    Data_temp = Data_temp.drop(f'CLA_3LYR_t{i}', axis=1)\n",
    "    Data_temp = Data_temp.drop(f'BASE_3LYR_t{i}', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "979bf3e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T08:35:54.439380Z",
     "start_time": "2021-07-27T08:35:54.224198Z"
    }
   },
   "outputs": [],
   "source": [
    "# 각 시간에 맞는 TAF로 나누기\n",
    "taf6 = [12,18,24]\n",
    "taf12 = [6,18,24]\n",
    "taf18 = [6,12,24]\n",
    "taf24 = [6,12,18]\n",
    "    \n",
    "# 각 시간에 맞는 taf 넣기\n",
    "data_taf = {}\n",
    "for i in range(6,30,6):\n",
    "    data_taf[f'Data_{i}'] = Data_temp    \n",
    "    data_taf[f'Data_{i}'] = data_taf[f'Data_{i}'].join(Data[f'WDIR_t{i}'])\n",
    "    data_taf[f'Data_{i}'] = data_taf[f'Data_{i}'].join(Data[f'WSPD_t{i}'])\n",
    "    data_taf[f'Data_{i}'] = data_taf[f'Data_{i}'].join(Data[f'WG_t{i}'])\n",
    "    data_taf[f'Data_{i}'] = data_taf[f'Data_{i}'].join(Data[f'VIS_t{i}'])\n",
    "    data_taf[f'Data_{i}'] = data_taf[f'Data_{i}'].join(Data[f'WC_t{i}'])\n",
    "    data_taf[f'Data_{i}'] = data_taf[f'Data_{i}'].join(Data[f'CLA_1LYR_t{i}'])\n",
    "    data_taf[f'Data_{i}'] = data_taf[f'Data_{i}'].join(Data[f'BASE_1LYR_t{i}'])\n",
    "    data_taf[f'Data_{i}'] = data_taf[f'Data_{i}'].join(Data[f'CLA_2LYR_t{i}'])\n",
    "    data_taf[f'Data_{i}'] = data_taf[f'Data_{i}'].join(Data[f'BASE_2LYR_t{i}'])\n",
    "    data_taf[f'Data_{i}'] = data_taf[f'Data_{i}'].join(Data[f'CLA_3LYR_t{i}'])\n",
    "    data_taf[f'Data_{i}'] = data_taf[f'Data_{i}'].join(Data[f'BASE_3LYR_t{i}'])\n",
    "    \n",
    "Data_6 = data_taf['Data_6']\n",
    "Data_12 = data_taf['Data_12']\n",
    "Data_18 = data_taf['Data_18']\n",
    "Data_24 = data_taf['Data_24']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "037f31ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T08:35:58.488964Z",
     "start_time": "2021-07-27T08:35:58.310924Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data shape :  (17520, 46)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EAD</th>\n",
       "      <th>EDD</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>DayName</th>\n",
       "      <th>Arpt_cond</th>\n",
       "      <th>P_Airp</th>\n",
       "      <th>P_AAR</th>\n",
       "      <th>P_ADR</th>\n",
       "      <th>Arrival_remainder</th>\n",
       "      <th>Departure_remainder</th>\n",
       "      <th>WD_850</th>\n",
       "      <th>WD_925</th>\n",
       "      <th>WD_1000</th>\n",
       "      <th>WS_850</th>\n",
       "      <th>WS_925</th>\n",
       "      <th>WS_1000</th>\n",
       "      <th>WD</th>\n",
       "      <th>WSPD</th>\n",
       "      <th>WS_GST</th>\n",
       "      <th>VIS</th>\n",
       "      <th>WC</th>\n",
       "      <th>RN</th>\n",
       "      <th>CA_TOT</th>\n",
       "      <th>CLA_1LYR</th>\n",
       "      <th>BASE_1LYR</th>\n",
       "      <th>CLA_2LYR</th>\n",
       "      <th>BASE_2LYR</th>\n",
       "      <th>CLA_3LYR</th>\n",
       "      <th>BASE_3LYR</th>\n",
       "      <th>CLA_4LYR</th>\n",
       "      <th>BASE_4LYR</th>\n",
       "      <th>RVR</th>\n",
       "      <th>WDIR_t6</th>\n",
       "      <th>WSPD_t6</th>\n",
       "      <th>WG_t6</th>\n",
       "      <th>VIS_t6</th>\n",
       "      <th>WC_t6</th>\n",
       "      <th>CLA_1LYR_t6</th>\n",
       "      <th>BASE_1LYR_t6</th>\n",
       "      <th>CLA_2LYR_t6</th>\n",
       "      <th>BASE_2LYR_t6</th>\n",
       "      <th>CLA_3LYR_t6</th>\n",
       "      <th>BASE_3LYR_t6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    EAD   EDD  year  month  day  hour  DayName  Arpt_cond  P_Airp  P_AAR  \\\n",
       "0   2.0  11.0  2018      1    1     0        1        1.0     1.0    0.0   \n",
       "1   1.0   5.0  2018      1    1     1        1        1.0     1.0    3.0   \n",
       "2   1.0   4.0  2018      1    1     2        1        1.0     1.0    0.0   \n",
       "3   0.0   1.0  2018      1    1     3        1        1.0     1.0    0.0   \n",
       "4  16.0   1.0  2018      1    1     4        1        1.0     1.0    2.0   \n",
       "\n",
       "   P_ADR  Arrival_remainder  Departure_remainder  WD_850  WD_925  WD_1000  \\\n",
       "0    0.0                0.0                  0.0   320.0   325.0    245.0   \n",
       "1   11.0                0.0                  0.0   320.0   325.0    245.0   \n",
       "2    4.0                1.0                  1.0   320.0   325.0    245.0   \n",
       "3    4.0                1.0                  0.0   320.0   325.0    245.0   \n",
       "4    1.0                0.0                  0.0   320.0   325.0    245.0   \n",
       "\n",
       "   WS_850  WS_925  WS_1000  WD  WSPD  WS_GST   VIS  WC   RN  CA_TOT  CLA_1LYR  \\\n",
       "0    28.0    19.0      3.0  34     5     0.0  1000   1  0.0       0       0.0   \n",
       "1    28.0    19.0      3.0   3     1     0.0  1000   1  0.0       0       0.0   \n",
       "2    28.0    19.0      3.0  35     1     0.0  1000   1  0.0       0       0.0   \n",
       "3    28.0    19.0      3.0   0     0     0.0  1000   1  0.0       0       0.0   \n",
       "4    28.0    19.0      3.0  19     1     0.0  1000   1  0.0       0       0.0   \n",
       "\n",
       "   BASE_1LYR  CLA_2LYR  BASE_2LYR  CLA_3LYR  BASE_3LYR  CLA_4LYR  BASE_4LYR  \\\n",
       "0      400.0       0.0      400.0       0.0      400.0       0.0      400.0   \n",
       "1      400.0       0.0      400.0       0.0      400.0       0.0      400.0   \n",
       "2      400.0       0.0      400.0       0.0      400.0       0.0      400.0   \n",
       "3      400.0       0.0      400.0       0.0      400.0       0.0      400.0   \n",
       "4      400.0       0.0      400.0       0.0      400.0       0.0      400.0   \n",
       "\n",
       "      RVR  WDIR_t6  WSPD_t6  WG_t6  VIS_t6  WC_t6  CLA_1LYR_t6  BASE_1LYR_t6  \\\n",
       "0  1000.0      0.0      0.0    0.0  9999.0      0            0         400.0   \n",
       "1  1000.0      0.0      0.0    0.0  9999.0      0            0         400.0   \n",
       "2  1000.0      0.0      0.0    0.0  9999.0      0            0         400.0   \n",
       "3  1000.0      0.0      0.0    0.0  9999.0      0            0         400.0   \n",
       "4  1000.0      0.0      0.0    0.0  9999.0      0            0         400.0   \n",
       "\n",
       "   CLA_2LYR_t6  BASE_2LYR_t6  CLA_3LYR_t6  BASE_3LYR_t6  \n",
       "0            0         400.0            0         400.0  \n",
       "1            0         400.0            0         400.0  \n",
       "2            0         400.0            0         400.0  \n",
       "3            0         400.0            0         400.0  \n",
       "4            0         400.0            0         400.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측할 시간에 맞는 Data로 넣기\n",
    "# 0-6 : Data_6 / 6-12 : Data_12 / 12-18 : Data_18 / 18-24 : Data_24\n",
    "Data_raw = Data_6\n",
    "Data_m = Data_6\n",
    "Data_m = Data_m.drop('AAR', axis=1)\n",
    "Data_m = Data_m.drop('ADR', axis=1)\n",
    "\n",
    "\n",
    "# Arrival\n",
    "y_a = Data_raw.AAR.to_numpy()\n",
    "X_a = Data_m.to_numpy()\n",
    "X_train_a, X_test_a, y_train_a, y_test_a = train_test_split(X_a, y_a, test_size = 0.1, random_state = seed)\n",
    "X_train_a, X_val_a, y_train_a, y_val_a = train_test_split(X_train_a, y_train_a, test_size=0.11, random_state = 13) \n",
    "\n",
    "\n",
    "# Departure\n",
    "y_d = Data_raw.ADR.to_numpy()\n",
    "X_d = Data_m.to_numpy()\n",
    "X_train_d, X_test_d, y_train_d, y_test_d = train_test_split(X_d, y_d, test_size = 0.1, random_state = seed)\n",
    "X_train_d, X_val_d, y_train_d, y_val_d = train_test_split(X_train_d, y_train_d, test_size=0.11, random_state = 13) \n",
    "\n",
    "# val은 hyperparameter 검증에 사용\n",
    "# 0.11 x 0.9 = 0.099\n",
    "\n",
    "print('Training Data shape : ', Data_m.shape)\n",
    "Data_m.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cd0f9c",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dc2b49",
   "metadata": {},
   "source": [
    "# NGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71be9bb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T08:36:09.878035Z",
     "start_time": "2021-07-27T08:36:09.868517Z"
    }
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    # filename = \"errors.log\",\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bde3ad0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T08:39:20.788153Z",
     "start_time": "2021-07-27T08:39:20.771636Z"
    }
   },
   "outputs": [],
   "source": [
    "b1 = DecisionTreeRegressor(criterion = \"friedman_mse\",                 # “mse”, “friedman_mse”, “mae”, “poisson”\n",
    "                                     min_samples_split = 3,             # The minimum number of samples required to split an internal node\n",
    "                                     min_samples_leaf = 1,              # The minimum number of samples required to be at a leaf node\n",
    "                                     min_weight_fraction_leaf = 0.0,    # The minimum weighted fraction of the sum total of weights required to be at a leaf node\n",
    "                                     max_depth = None,                  # The maximum depth of the tree\n",
    "                                     max_leaf_nodes = 127,              # Grow a tree with 'max_leaf_nodes' in best-first fashion\n",
    "                                     splitter = \"best\",                 # The strategy used to choose the split at each node\n",
    "                                     random_state = seed)\n",
    "b2 = DecisionTreeRegressor(criterion = \"friedman_mse\",                 # “mse”, “friedman_mse”, “mae”, “poisson”\n",
    "                                     min_samples_split = 3,             # The minimum number of samples required to split an internal node\n",
    "                                     min_samples_leaf = 1,              # The minimum number of samples required to be at a leaf node\n",
    "                                     min_weight_fraction_leaf = 0.0,    # The minimum weighted fraction of the sum total of weights required to be at a leaf node\n",
    "                                     max_depth = None,                  # The maximum depth of the tree\n",
    "                                     max_leaf_nodes = 255,              # Grow a tree with 'max_leaf_nodes' in best-first fashion\n",
    "                                     splitter = \"best\",                 # The strategy used to choose the split at each node\n",
    "                                     random_state = seed)\n",
    "b3 = DecisionTreeRegressor(criterion = \"friedman_mse\",                 # “mse”, “friedman_mse”, “mae”, “poisson”\n",
    "                                     min_samples_split = 3,             # The minimum number of samples required to split an internal node\n",
    "                                     min_samples_leaf = 1,              # The minimum number of samples required to be at a leaf node\n",
    "                                     min_weight_fraction_leaf = 0.0,    # The minimum weighted fraction of the sum total of weights required to be at a leaf node\n",
    "                                     max_depth = None,                  # The maximum depth of the tree\n",
    "                                     max_leaf_nodes = 63,              # Grow a tree with 'max_leaf_nodes' in best-first fashion\n",
    "                                     splitter = \"best\",                 # The strategy used to choose the split at each node\n",
    "                                     random_state = seed)\n",
    "\n",
    "\n",
    "space = {\n",
    "    'learning_rate':hp.uniform('learning_rate', .0001, 0.01),\n",
    "    'minibatch_frac':hp.uniform('minibatch_frac', 0.5, 1.0),\n",
    "    'col_sample':hp.uniform('col_sample', 0.5, 1.0),\n",
    "    'Base':hp.choice('Base', [b1, b2, b3])\n",
    "}\n",
    "\n",
    "default_params = {\"n_estimators\":10000000,\n",
    "                  \"verbose_eval\":1,\n",
    "                  \"random_state\":13}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f270548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_a(params):\n",
    "    \n",
    "    params.update(default_params)\n",
    "    \n",
    "    print(params)\n",
    "    ngb_arrival = NGBRegressor(**params).fit(X_train_a, y_train_a,\n",
    "                                             X_val = X_val_a, \n",
    "                                             Y_val = y_val_a, \n",
    "                                             early_stopping_rounds = 10)\n",
    "    loss = ngb_arrival.evals_result['val']['LOGSCORE'][ngb_arrival.best_val_loss_itr]\n",
    "    logger.info(params)\n",
    "    results = {'loss':loss, 'status':STATUS_OK}\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ab6a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_d(params):\n",
    "    \n",
    "    params.update(default_params)\n",
    "    \n",
    "    print(params)\n",
    "    ngb_departure = NGBRegressor(**params).fit(X_train_d, y_train_d,\n",
    "                                             X_val = X_val_d, \n",
    "                                             Y_val = y_val_d, \n",
    "                                             early_stopping_rounds = 10)\n",
    "    loss = ngb_departure.evals_result['val']['LOGSCORE'][ngb_departure.best_val_loss_itr]\n",
    "    logger.info(params)\n",
    "    results = {'loss':loss, 'status':STATUS_OK}\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "439b3d6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T05:24:57.396745Z",
     "start_time": "2021-07-26T05:21:41.120068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=3.8335 val_loss=3.8420 scale=2.0000 norm=18.0966\n",
      "[iter 100] loss=3.6192 val_loss=3.6266 scale=2.0000 norm=15.1542\n",
      "[iter 200] loss=3.4824 val_loss=3.4923 scale=2.0000 norm=12.6807\n",
      "[iter 300] loss=3.3690 val_loss=3.3851 scale=2.0000 norm=10.6507\n",
      "[iter 400] loss=3.2709 val_loss=3.2877 scale=2.0000 norm=9.1246\n",
      "[iter 500] loss=3.1780 val_loss=3.1974 scale=2.0000 norm=7.8865\n",
      "[iter 600] loss=3.0862 val_loss=3.1121 scale=2.0000 norm=6.8468\n",
      "[iter 700] loss=3.0017 val_loss=3.0309 scale=2.0000 norm=6.1067\n",
      "[iter 800] loss=2.9197 val_loss=2.9536 scale=2.0000 norm=5.4891\n",
      "[iter 900] loss=2.8352 val_loss=2.8799 scale=2.0000 norm=4.9407\n",
      "[iter 1000] loss=2.7577 val_loss=2.8104 scale=2.0000 norm=4.5621\n",
      "[iter 1100] loss=2.6776 val_loss=2.7454 scale=2.0000 norm=4.2127\n",
      "[iter 1200] loss=2.6059 val_loss=2.6850 scale=2.0000 norm=3.9881\n",
      "[iter 1300] loss=2.5326 val_loss=2.6295 scale=2.0000 norm=3.7662\n",
      "[iter 1400] loss=2.4630 val_loss=2.5796 scale=2.0000 norm=3.5921\n",
      "[iter 1500] loss=2.3949 val_loss=2.5357 scale=2.0000 norm=3.4220\n",
      "[iter 1600] loss=2.3311 val_loss=2.4982 scale=2.0000 norm=3.3057\n",
      "[iter 1700] loss=2.2676 val_loss=2.4670 scale=2.0000 norm=3.2297\n",
      "[iter 1800] loss=2.2090 val_loss=2.4430 scale=2.0000 norm=3.1297\n",
      "[iter 1900] loss=2.1522 val_loss=2.4263 scale=2.0000 norm=3.0550\n",
      "[iter 2000] loss=2.1004 val_loss=2.4170 scale=2.0000 norm=2.9987\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL2087 (val_loss=2.4147)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NGBRegressor(Base=DecisionTreeRegressor(criterion='friedman_mse',\n",
       "                                        max_leaf_nodes=127, min_samples_split=3,\n",
       "                                        random_state=1),\n",
       "             col_sample=0.8, learning_rate=0.001, minibatch_frac=0.8,\n",
       "             n_estimators=10000000,\n",
       "             random_state=RandomState(MT19937) at 0x25D3D033540, tol=1e-05)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Arrival\n",
    "\n",
    "tree_learner = DecisionTreeRegressor(criterion = \"friedman_mse\",                 # “mse”, “friedman_mse”, “mae”, “poisson”\n",
    "                                     min_samples_split = 3,             # The minimum number of samples required to split an internal node\n",
    "                                     min_samples_leaf = 1,              # The minimum number of samples required to be at a leaf node\n",
    "                                     min_weight_fraction_leaf = 0.0,    # The minimum weighted fraction of the sum total of weights required to be at a leaf node\n",
    "                                     max_depth = None,                  # The maximum depth of the tree\n",
    "                                     max_leaf_nodes = 127,              # Grow a tree with 'max_leaf_nodes' in best-first fashion\n",
    "                                     splitter = \"best\",                 # The strategy used to choose the split at each node\n",
    "                                     random_state = seed)\n",
    "\n",
    "\n",
    "ngb_arrival = NGBRegressor(Dist = Normal,               # A distribution from ngboost.distns : Normal, LogNormal, Exponential...\n",
    "                           Score = MLE,            # rule to compare probabilistic predictions P̂ to the observed data y, from ngboost.scores : LogScore, CRPScore...\n",
    "                           Base = tree_learner,         # base learner to use in the boosting algorithm\n",
    "                           natural_gradient = True,     # logical flag indicating whether the natural gradient should be used\n",
    "                           verbose = True,\n",
    "                           n_estimators = 10000000, \n",
    "                           learning_rate = 0.001,\n",
    "                           minibatch_frac = 0.8,        # the percent subsample of rows to use in each boosting iteration\n",
    "                           col_sample = 0.8,            \n",
    "                           tol = 1e-5,                  # numerical tolerance to be used in optimization\n",
    "                           random_state = 13)\n",
    "\n",
    "ngb_arrival.fit(X_train_a, y_train_a,\n",
    "                X_val = X_val_a,\n",
    "                Y_val = y_val_a,\n",
    "                sample_weight = None,                   # Weights of training data\n",
    "                val_sample_weight = None,               # Weights of eval data\n",
    "                train_loss_monitor = None,              # custom score or set of scores to track on the training set during training\n",
    "                val_loss_monitor = None,                # custom score or set of scores to track on the validation set during training\n",
    "                early_stopping_rounds = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d55ad61f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T05:28:13.761809Z",
     "start_time": "2021-07-26T05:24:57.398709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=3.9479 val_loss=3.9350 scale=2.0000 norm=20.8821\n",
      "[iter 100] loss=3.7300 val_loss=3.7299 scale=2.0000 norm=17.1325\n",
      "[iter 200] loss=3.5941 val_loss=3.5947 scale=2.0000 norm=14.3145\n",
      "[iter 300] loss=3.4794 val_loss=3.4836 scale=2.0000 norm=11.9403\n",
      "[iter 400] loss=3.3748 val_loss=3.3821 scale=2.0000 norm=10.0322\n",
      "[iter 500] loss=3.2743 val_loss=3.2871 scale=2.0000 norm=8.4558\n",
      "[iter 600] loss=3.1806 val_loss=3.1965 scale=2.0000 norm=7.2549\n",
      "[iter 700] loss=3.0898 val_loss=3.1093 scale=2.0000 norm=6.3017\n",
      "[iter 800] loss=2.9978 val_loss=3.0256 scale=2.0000 norm=5.4791\n",
      "[iter 900] loss=2.9094 val_loss=2.9450 scale=2.0000 norm=4.8926\n",
      "[iter 1000] loss=2.8282 val_loss=2.8680 scale=2.0000 norm=4.4429\n",
      "[iter 1100] loss=2.7422 val_loss=2.7947 scale=2.0000 norm=4.0576\n",
      "[iter 1200] loss=2.6576 val_loss=2.7255 scale=2.0000 norm=3.7433\n",
      "[iter 1300] loss=2.5787 val_loss=2.6611 scale=2.0000 norm=3.5249\n",
      "[iter 1400] loss=2.4975 val_loss=2.6016 scale=2.0000 norm=3.3067\n",
      "[iter 1500] loss=2.4243 val_loss=2.5478 scale=2.0000 norm=3.1704\n",
      "[iter 1600] loss=2.3481 val_loss=2.5003 scale=2.0000 norm=3.0231\n",
      "[iter 1700] loss=2.2767 val_loss=2.4596 scale=2.0000 norm=2.9179\n",
      "[iter 1800] loss=2.2075 val_loss=2.4259 scale=2.0000 norm=2.8264\n",
      "[iter 1900] loss=2.1442 val_loss=2.4000 scale=2.0000 norm=2.7695\n",
      "[iter 2000] loss=2.0814 val_loss=2.3821 scale=2.0000 norm=2.6944\n",
      "[iter 2100] loss=2.0180 val_loss=2.3731 scale=2.0000 norm=2.6143\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL2146 (val_loss=2.3719)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NGBRegressor(Base=DecisionTreeRegressor(criterion='friedman_mse',\n",
       "                                        max_leaf_nodes=127, min_samples_split=3,\n",
       "                                        random_state=1),\n",
       "             col_sample=0.8, learning_rate=0.001, minibatch_frac=0.8,\n",
       "             n_estimators=10000000,\n",
       "             random_state=RandomState(MT19937) at 0x25D3D0C0840, tol=1e-05)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Departure\n",
    "\n",
    "tree_learner = DecisionTreeRegressor(criterion = \"friedman_mse\",                 # “mse”, “friedman_mse”, “mae”, “poisson”\n",
    "                                     min_samples_split = 3,             # The minimum number of samples required to split an internal node\n",
    "                                     min_samples_leaf = 1,              # The minimum number of samples required to be at a leaf node\n",
    "                                     min_weight_fraction_leaf = 0.0,    # The minimum weighted fraction of the sum total of weights required to be at a leaf node\n",
    "                                     max_depth = None,                  # The maximum depth of the tree\n",
    "                                     max_leaf_nodes = 127,              # Grow a tree with 'max_leaf_nodes' in best-first fashion\n",
    "                                     splitter = \"best\",                 # The strategy used to choose the split at each node\n",
    "                                     random_state = seed)\n",
    "\n",
    "\n",
    "ngb_departure = NGBRegressor(Dist = Normal,               # A distribution from ngboost.distns : Normal, LogNormal, Exponential...\n",
    "                             Score = MLE,            # rule to compare probabilistic predictions P̂ to the observed data y, from ngboost.scores : LogScore, CRPScore...\n",
    "                             Base = tree_learner,         # base learner to use in the boosting algorithm\n",
    "                             natural_gradient = True,     # logical flag indicating whether the natural gradient should be used\n",
    "                             verbose = True,\n",
    "                             n_estimators = 10000000, \n",
    "                             learning_rate = 0.001,\n",
    "                             minibatch_frac = 0.8,        # the percent subsample of rows to use in each boosting iteration\n",
    "                             col_sample = 0.8,            \n",
    "                             tol = 1e-5,                  # numerical tolerance to be used in optimization\n",
    "                             random_state = 13)\n",
    "\n",
    "\n",
    "ngb_departure.fit(X_train_d, y_train_d,\n",
    "                X_val = X_val_d,\n",
    "                Y_val = y_val_d,\n",
    "                sample_weight = None,                   # Weights of training data\n",
    "                val_sample_weight = None,               # Weights of eval data\n",
    "                train_loss_monitor = None,              # custom score or set of scores to track on the training set during training\n",
    "                val_loss_monitor = None,                # custom score or set of scores to track on the validation set during training\n",
    "                early_stopping_rounds = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a784943",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T05:28:33.127905Z",
     "start_time": "2021-07-26T05:28:13.764298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set RMSE :  1.668103108250137\n",
      "Test set RMSE :  2.711712704987977\n",
      "Train set R^2 :  0.9776415087323574\n",
      "Test set R^2 :  0.9391631861609595\n"
     ]
    }
   ],
   "source": [
    "# Arrival\n",
    "\n",
    "print(\"Train set RMSE : \" , np.sqrt(mean_squared_error(y_train_a, ngb_arrival.pred_dist(X_train_a).loc)))\n",
    "print(\"Test set RMSE : \" , np.sqrt(mean_squared_error(y_test_a, ngb_arrival.pred_dist(X_test_a).loc)))\n",
    "\n",
    "print(\"Train set R^2 : \" , r2_score(y_train_a, ngb_arrival.pred_dist(X_train_a).loc))\n",
    "print(\"Test set R^2 : \" , r2_score(y_test_a, ngb_arrival.pred_dist(X_test_a).loc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14b14166",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T05:28:53.538733Z",
     "start_time": "2021-07-26T05:28:33.129891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set RMSE :  1.4508842206469068\n",
      "Test set RMSE :  2.6205980459942544\n",
      "Train set R^2 :  0.9864475680404998\n",
      "Test set R^2 :  0.9536169941521409\n"
     ]
    }
   ],
   "source": [
    "# Departure\n",
    "\n",
    "print(\"Train set RMSE : \" , np.sqrt(mean_squared_error(y_train_d, ngb_departure.pred_dist(X_train_d).loc)))\n",
    "print(\"Test set RMSE : \" , np.sqrt(mean_squared_error(y_test_d, ngb_departure.pred_dist(X_test_d).loc)))\n",
    "\n",
    "print(\"Train set R^2 : \" , r2_score(y_train_d, ngb_departure.pred_dist(X_train_d).loc))\n",
    "print(\"Test set R^2 : \" , r2_score(y_test_d, ngb_departure.pred_dist(X_test_d).loc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ffa267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7753ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95bed2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e159385",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T05:29:03.312625Z",
     "start_time": "2021-07-26T05:28:53.540735Z"
    }
   },
   "outputs": [],
   "source": [
    "y_a_pred = ngb_arrival.pred_dist(X_a)\n",
    "predictions = pd.DataFrame(y_a_pred.loc, columns=['Predictions'])\n",
    "predictions_sd = pd.DataFrame(y_a_pred.scale, columns=['Standard Deviation'])\n",
    "predictions_upper = pd.DataFrame(y_a_pred.dist.interval(0.95)[1], columns=['95% Predictions_upper'])    # 95% prediction interval\n",
    "predictions_lower = pd.DataFrame(y_a_pred.dist.interval(0.95)[0], columns=['95% Predictions_lower'])\n",
    "Actual_AAR = pd.DataFrame({'Actual AAR':y_a})\n",
    "Date = pd.date_range(start='1/1/2019', end='12/31/2019 23:00', freq = '1H')\n",
    "\n",
    "prediction =  pd.concat([pd.DataFrame({'Date':Date}), Actual_AAR, predictions, predictions_sd, \n",
    "                         predictions_upper, predictions_lower], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdd8f22a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T05:29:03.328631Z",
     "start_time": "2021-07-26T05:29:03.313642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Actual AAR</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Standard Deviation</th>\n",
       "      <th>95% Predictions_upper</th>\n",
       "      <th>95% Predictions_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.474189</td>\n",
       "      <td>2.913600</td>\n",
       "      <td>10.184741</td>\n",
       "      <td>-1.236363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 01:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.225787</td>\n",
       "      <td>3.097105</td>\n",
       "      <td>8.296000</td>\n",
       "      <td>-3.844426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 02:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.784956</td>\n",
       "      <td>3.161070</td>\n",
       "      <td>7.980540</td>\n",
       "      <td>-4.410629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 03:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.682507</td>\n",
       "      <td>3.049627</td>\n",
       "      <td>11.659667</td>\n",
       "      <td>-0.294652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 04:00:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.936671</td>\n",
       "      <td>2.103743</td>\n",
       "      <td>25.059932</td>\n",
       "      <td>16.813410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8755</th>\n",
       "      <td>2019-12-31 19:00:00</td>\n",
       "      <td>26.0</td>\n",
       "      <td>28.490084</td>\n",
       "      <td>2.584104</td>\n",
       "      <td>33.554834</td>\n",
       "      <td>23.425334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8756</th>\n",
       "      <td>2019-12-31 20:00:00</td>\n",
       "      <td>39.0</td>\n",
       "      <td>35.986559</td>\n",
       "      <td>3.638105</td>\n",
       "      <td>43.117115</td>\n",
       "      <td>28.856004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8757</th>\n",
       "      <td>2019-12-31 21:00:00</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.292020</td>\n",
       "      <td>2.240638</td>\n",
       "      <td>27.683590</td>\n",
       "      <td>18.900450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>2019-12-31 22:00:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.232461</td>\n",
       "      <td>2.245879</td>\n",
       "      <td>24.634304</td>\n",
       "      <td>15.830618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>2019-12-31 23:00:00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.360592</td>\n",
       "      <td>2.610558</td>\n",
       "      <td>14.477191</td>\n",
       "      <td>4.243993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8760 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date  Actual AAR  Predictions  Standard Deviation  \\\n",
       "0    2019-01-01 00:00:00         4.0     4.474189            2.913600   \n",
       "1    2019-01-01 01:00:00         2.0     2.225787            3.097105   \n",
       "2    2019-01-01 02:00:00         0.0     1.784956            3.161070   \n",
       "3    2019-01-01 03:00:00         6.0     5.682507            3.049627   \n",
       "4    2019-01-01 04:00:00        20.0    20.936671            2.103743   \n",
       "...                  ...         ...          ...                 ...   \n",
       "8755 2019-12-31 19:00:00        26.0    28.490084            2.584104   \n",
       "8756 2019-12-31 20:00:00        39.0    35.986559            3.638105   \n",
       "8757 2019-12-31 21:00:00        23.0    23.292020            2.240638   \n",
       "8758 2019-12-31 22:00:00        20.0    20.232461            2.245879   \n",
       "8759 2019-12-31 23:00:00         9.0     9.360592            2.610558   \n",
       "\n",
       "      95% Predictions_upper  95% Predictions_lower  \n",
       "0                 10.184741              -1.236363  \n",
       "1                  8.296000              -3.844426  \n",
       "2                  7.980540              -4.410629  \n",
       "3                 11.659667              -0.294652  \n",
       "4                 25.059932              16.813410  \n",
       "...                     ...                    ...  \n",
       "8755              33.554834              23.425334  \n",
       "8756              43.117115              28.856004  \n",
       "8757              27.683590              18.900450  \n",
       "8758              24.634304              15.830618  \n",
       "8759              14.477191               4.243993  \n",
       "\n",
       "[8760 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232134b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T06:03:57.711980Z",
     "start_time": "2021-07-15T06:03:57.684460Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_result(prediction, start=0, end=10):   \n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(22, 10))\n",
    "    plt.fill_between(prediction['Date'][start:end], prediction['95% Predictions_lower'][start:end],  prediction['95% Predictions_upper'][start:end], \n",
    "                     label = '95% Prediction Interval', color='gray', alpha=0.5)\n",
    "    plt.plot(prediction['Date'][start:end], prediction['Predictions'][start:end], label = 'Predictions', lw=2)\n",
    "    plt.scatter(prediction['Date'][start:end], prediction['Predictions'][start:end], lw=3)\n",
    "    plt.scatter(prediction['Date'][start:end], prediction['Actual AAR'][start:end], label = 'Actual AAR', color='r', lw=3)\n",
    "\n",
    "    ax.legend(fontsize = 15)\n",
    "    #plt.title('Hourly Power Consumption Actual vs. Predicted Values with Prediction Intervals')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Arrivals per hour')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21152d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T06:03:58.938008Z",
     "start_time": "2021-07-15T06:03:58.685943Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_result(prediction, start = 8230, end = 8300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd241a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9e5e16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe50bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e21330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d673c5e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75a8a268",
   "metadata": {},
   "source": [
    "## NGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635e08c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T11:25:42.621308Z",
     "start_time": "2021-07-14T11:25:42.591003Z"
    }
   },
   "outputs": [],
   "source": [
    "X, Y = load_boston(True)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370f60c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T13:13:17.860090Z",
     "start_time": "2021-07-14T13:13:17.783899Z"
    }
   },
   "outputs": [],
   "source": [
    "# prediction\n",
    "Y_preds = ngb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f98b50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T13:13:53.299599Z",
     "start_time": "2021-07-14T13:13:53.284600Z"
    }
   },
   "outputs": [],
   "source": [
    "# estimated distributional parameters at a set of point\n",
    "Y_dists = ngb.pred_dist(X_test)\n",
    "\n",
    "Y_dists[0:5].params    \n",
    "\n",
    "# loc : mean\n",
    "# scale : standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b15ecec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T11:25:59.538442Z",
     "start_time": "2021-07-14T11:25:59.526411Z"
    }
   },
   "outputs": [],
   "source": [
    "# test Mean Squared Error\n",
    "test_MSE = mean_squared_error(Y_preds, Y_test)\n",
    "print('Test MSE', test_MSE)\n",
    "\n",
    "# test Negative Log Likelihood\n",
    "test_NLL = -Y_dists.logpdf(Y_test).mean()\n",
    "print('Test NLL', test_NLL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65258c05",
   "metadata": {},
   "source": [
    "## Survival Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91f86cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ngboost import NGBSurvival\n",
    "from ngboost.distns import LogNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000b121c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159c16eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b673d0a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c768413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b651557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c4eabf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15917e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0d591c9",
   "metadata": {},
   "source": [
    "# Distribution Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51debc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "214.475px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
