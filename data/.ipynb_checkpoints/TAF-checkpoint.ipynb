{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c00b39a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T04:16:20.634427Z",
     "start_time": "2021-07-21T04:16:20.127437Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import re\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad032179",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T04:16:20.746481Z",
     "start_time": "2021-07-21T04:16:20.715424Z"
    }
   },
   "outputs": [],
   "source": [
    "# 0. 데이터 가져오기\n",
    "\n",
    "data = pd.read_csv('.\\\\Weather\\\\RKSI_TAF.csv', sep='\\n', header = None)\n",
    "\n",
    "data_2018 = pd.read_csv('.\\\\Weather\\\\RKSI_TAF_2018.csv', sep='\\n', header = None)\n",
    "\n",
    "TAF_data = list(np.zeros(len(data)))\n",
    "TAF_data_2018 = list(np.zeros(len(data_2018)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e551d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "\n",
    "# 이부분을 바꿔서 2018도 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf6833fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T04:17:02.048226Z",
     "start_time": "2021-07-21T04:16:21.565761Z"
    }
   },
   "outputs": [],
   "source": [
    "for l in range(0,len(data_2018)):     ##############################################################\n",
    "    Data = data_2018.iloc[l,0]        ##############################################################\n",
    "    \n",
    "    # 1. Pattern\n",
    "    pattern_issue = '[0-9].....Z'\n",
    "    pattern_date = '[0-9]+/[0-9]{2,4}'\n",
    "    pattern_taf = 'TX........Z|TX.......Z'             # BECMG, TEMPO 전 text 찾는데 사용\n",
    "    pattern_wind = '\\s[0-9]...[0-9][A-Z]'              # 단, 100KT이상은 잡을 수 X        \n",
    "    pattern_vis = '\\s[0-9]..[0-9]\\s'               \n",
    "    pattern_cavok = '\\sC[A-Z][A-Z][A-Z][A-Z]\\s'\n",
    "    pattern_wc = 'NSW|TS|DZ|RA|SN|SG|IC|PL|GR|GS|BR|FG|FU|VA|DU|SA|HZ|SQ|FC|SS|DS'\n",
    "    pattern_cloud = '[FSBO][A-Z][A-Z]..[0-9]'\n",
    "    pattern_chg = 'BECMG|TEMPO'\n",
    "    regex = re.compile(pattern_date)\n",
    "    search = regex.search(Data)\n",
    "    # search.group()\n",
    "    # search.start()\n",
    "    # search.end()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 2. 발생시간\n",
    "    yymm = Data[re.search('[0-9]...+-[0-9].+-[0-9].', Data).start() : re.search('[0-9]...+-[0-9].+-[0-9].', Data).start()+8] \n",
    "    ddHHMM = Data[re.search(pattern_issue, Data).start() : re.search(pattern_issue, Data).start()+6]\n",
    "    nextyear = Data[re.search('[0-9]...+-[0-9].+-[0-9].', Data).start()+5 : re.search('[0-9]...+-[0-9].+-[0-9].', Data).start()+7] + Data[re.search(pattern_issue, Data).start() : re.search(pattern_issue, Data).start()+2]\n",
    "\n",
    "    start = Data[re.search(pattern_date, Data).start() : re.search(pattern_date, Data).start()+4]\n",
    "    end = Data[re.search(pattern_date, Data).start()+5 : re.search(pattern_date, Data).start()+9]\n",
    "    start_time = datetime.datetime.strptime(yymm + start ,'%Y-%m-%d%H') + datetime.timedelta(hours = 9)     # india time으로 바꿈!\n",
    "    if (yymm+end)[-2:] == '24':\n",
    "        end_time = pd.to_datetime((yymm+end)[:-2], format = '%Y-%m-%d') + pd.Timedelta(days=1) + pd.Timedelta(hours=9)\n",
    "        end_time = end_time.to_pydatetime()\n",
    "    else:\n",
    "        end_time = datetime.datetime.strptime(yymm + end ,'%Y-%m-%d%H') + datetime.timedelta(hours = 9)\n",
    "        \n",
    "    if end_time > start_time:\n",
    "        end_time = end_time\n",
    "    else: \n",
    "        end_time = end_time + relativedelta(months=1)\n",
    "        start_time = start_time\n",
    "        \n",
    "    if nextyear =='1231':\n",
    "        start_time = start_time + relativedelta(months=1)\n",
    "        end_time = end_time + relativedelta(months=1)\n",
    "    else:\n",
    "        start_time = start_time\n",
    "        end_time = end_time\n",
    "            \n",
    "    column = ['WDIR', 'WSPD', 'WG', 'VIS', 'WC', 'CLA_1LYR', 'BASE_1LYR', 'CLA_2LYR', 'BASE_2LYR', 'CLA_3LYR', 'BASE_3LYR']\n",
    "    Time = pd.date_range(start = start_time, end = end_time, freq = 'H')\n",
    "    TAF = pd.DataFrame([], index = Time)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 3. BECMG, TEMPO 들어간거 찾기\n",
    "    chg_iter = re.finditer(pattern_chg, Data)                \n",
    "    chg = list(chg_iter)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 4. 첫번쨰 맨 앞 예보 꺼내고 삭제하기\n",
    "\n",
    "    # BECMG, TEMPO 앞만 남기고 자르기\n",
    "    if len(chg) != 0:\n",
    "        Data = Data[:chg[-len(chg)].end()-6]              \n",
    "\n",
    "    # 시작시간, 종료시간\n",
    "    start = Data[re.search(pattern_date, Data).start() : re.search(pattern_date, Data).start()+4]\n",
    "    end = Data[re.search(pattern_date, Data).start()+5 : re.search(pattern_date, Data).start()+9]\n",
    "    start_time = datetime.datetime.strptime(yymm + start ,'%Y-%m-%d%H') + datetime.timedelta(hours = 9)     # india time으로 바꿈! \n",
    "    if (yymm+end)[-2:] == '24':\n",
    "        end_time = pd.to_datetime((yymm+end)[:-2], format = '%Y-%m-%d') + pd.Timedelta(days=1) + pd.Timedelta(hours=9)\n",
    "        end_time = end_time.to_pydatetime()\n",
    "    else:\n",
    "        end_time = datetime.datetime.strptime(yymm + end ,'%Y-%m-%d%H') + datetime.timedelta(hours = 9)\n",
    "    \n",
    "    if end_time > start_time:\n",
    "        end_time = end_time\n",
    "    else: \n",
    "        end_time = end_time + relativedelta(months=1)\n",
    "        start_time = start_time\n",
    "    if nextyear =='1231':\n",
    "        start_time = start_time + relativedelta(months=1)\n",
    "        end_time = end_time + relativedelta(months=1)\n",
    "    else:\n",
    "        start_time = start_time\n",
    "        end_time = end_time\n",
    "        \n",
    "    # 바람\n",
    "    wind_f = re.search(pattern_wind, Data)\n",
    "    if wind_f != None:\n",
    "        if wind_f.group()[-1] == 'K':\n",
    "            wind = Data[re.search(pattern_wind, Data).start()+1 : re.search(pattern_wind, Data).start()+8]\n",
    "            WDIR = wind[0:3]\n",
    "            WSPD = wind[3:5]\n",
    "            WG = '0'\n",
    "        else:\n",
    "            wind = Data[re.search(pattern_wind, Data).start()+1 : re.search(pattern_wind, Data).start()+11]\n",
    "            WDIR = wind[0:3]\n",
    "            WSPD = wind[3:5]\n",
    "            WG = wind[6:8]\n",
    "    else:\n",
    "        WDIR = '0'\n",
    "        WSPD = '0'\n",
    "        WG = '0'\n",
    "\n",
    "    # 시정   \n",
    "    if len(re.findall(pattern_cavok, Data)) == 0:\n",
    "        vis = re.search(pattern_vis, Data)\n",
    "        if vis != None:\n",
    "            VIS = Data[re.search(pattern_vis, Data).start()+1 : re.search(pattern_vis, Data).start()+5]\n",
    "        else:\n",
    "            VIS = None\n",
    "    else:\n",
    "        vis = re.search(pattern_cavok, Data)\n",
    "        VIS = '9999'    \n",
    "\n",
    "    # 현천\n",
    "    wc = re.search(pattern_wc, Data)\n",
    "    if wc != None:\n",
    "        if wc.group() == 'NSW':\n",
    "            WC = '0'\n",
    "        else:\n",
    "            WC = wc.group()\n",
    "    else:\n",
    "        WC = '0'\n",
    "\n",
    "    # 구름\n",
    "    taf_find = re.finditer(pattern_taf, Data)        \n",
    "    taf_data = Data[:list(taf_find)[-1].start()]\n",
    "    cloud = re.finditer(pattern_cloud, taf_data) \n",
    "    tcloud = list(cloud)\n",
    "    if len(tcloud) == 3:\n",
    "        CLA_1LYR = Data[tcloud[0].start() : tcloud[0].start()+3]\n",
    "        BASE_1LYR = Data[tcloud[0].start()+3 : tcloud[0].start()+6]\n",
    "        CLA_2LYR = Data[tcloud[1].start() : tcloud[1].start()+3]\n",
    "        BASE_2LYR = Data[tcloud[1].start()+3 : tcloud[1].start()+6]\n",
    "        CLA_3LYR = Data[tcloud[2].start() : tcloud[2].start()+3]\n",
    "        BASE_3LYR = Data[tcloud[2].start()+3 : tcloud[2].start()+6]\n",
    "    elif len(tcloud) == 2:\n",
    "        CLA_1LYR = Data[tcloud[0].start() : tcloud[0].start()+3]\n",
    "        BASE_1LYR = Data[tcloud[0].start()+3 : tcloud[0].start()+6]\n",
    "        CLA_2LYR = Data[tcloud[1].start() : tcloud[1].start()+3]\n",
    "        BASE_2LYR = Data[tcloud[1].start()+3 : tcloud[1].start()+6]\n",
    "        CLA_3LYR = '0'\n",
    "        BASE_3LYR = '400'\n",
    "    elif len(tcloud) == 1:\n",
    "        CLA_1LYR = Data[tcloud[0].start() : tcloud[0].start()+3]\n",
    "        BASE_1LYR = Data[tcloud[0].start()+3 : tcloud[0].start()+6]\n",
    "        CLA_2LYR = '0'\n",
    "        BASE_2LYR = '400'\n",
    "        CLA_3LYR = '0'\n",
    "        BASE_3LYR = '400'\n",
    "    elif len(tcloud) == 0:\n",
    "        CLA_1LYR = '0'\n",
    "        BASE_1LYR = '400'\n",
    "        CLA_2LYR = '0'\n",
    "        BASE_2LYR = '400'\n",
    "        CLA_3LYR = '0'\n",
    "        BASE_3LYR = '400'\n",
    "    else: \n",
    "        CLA_1LYR = Data[tcloud[0].start() : tcloud[0].start()+3]\n",
    "        BASE_1LYR = Data[tcloud[0].start()+3 : tcloud[0].start()+6]\n",
    "        CLA_2LYR = Data[tcloud[1].start() : tcloud[1].start()+3]\n",
    "        BASE_2LYR = Data[tcloud[1].start()+3 : tcloud[1].start()+6]\n",
    "        CLA_3LYR = Data[tcloud[2].start() : tcloud[2].start()+3]\n",
    "        BASE_3LYR = Data[tcloud[2].start()+3 : tcloud[2].start()+6]\n",
    "\n",
    "    weather = [WDIR, WSPD, WG, VIS, WC, CLA_1LYR, BASE_1LYR, CLA_2LYR, BASE_2LYR, CLA_3LYR, BASE_3LYR]\n",
    "\n",
    "    Data = data_2018.iloc[l,0]         ##############################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 5. TAF 안에 넣기\n",
    "\n",
    "    temp_time= pd.date_range(start = start_time, end = end_time, freq = 'H')\n",
    "    Weather = [weather]\n",
    "\n",
    "    for i in range(len(temp_time)-1):\n",
    "        Weather.append(weather)\n",
    "\n",
    "    Wx = pd.DataFrame(Weather, index = temp_time, columns = column)\n",
    "    TAF = TAF.combine_first(Wx)\n",
    "    \n",
    "    # 5* issue date 붙이기\n",
    "    issue_date = pd.DataFrame({'issue_time': [str(start_time)]*len(TAF)}, index = TAF.index)\n",
    "    TAF = issue_date.join(TAF)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 6. BECMG, TEMPO 부분 뒤에서 부터 데이터 꺼내오기\n",
    "\n",
    "    iter = len(chg)\n",
    "\n",
    "    weathers = list(np.zeros(len(chg)))\n",
    "    durs = list(np.zeros(len(chg)))\n",
    "\n",
    "    for i in range(1, iter+1):\n",
    "\n",
    "        if len(chg) == 0:\n",
    "            temp = ''\n",
    "            continue  \n",
    "\n",
    "        # 마지막 BECMG, TEMPO 뒤만 남기고 자르기\n",
    "        temp = Data[chg[-1].end()-6:]\n",
    "        \n",
    "        # 시작시간, 종료시간\n",
    "        temp_start = temp[re.search(pattern_date, temp).start() : re.search(pattern_date, temp).start()+4]   \n",
    "        temp_end = temp[re.search(pattern_date, temp).start()+5 : re.search(pattern_date, temp).start()+9]\n",
    "        temp_start_time = datetime.datetime.strptime(yymm + temp_start ,'%Y-%m-%d%H') + datetime.timedelta(hours = 9)     \n",
    "        if (yymm+temp_end)[-2:] == '24':\n",
    "            temp_end_time = pd.to_datetime((yymm+temp_end)[:-2], format = '%Y-%m-%d') + pd.Timedelta(days=1) + pd.Timedelta(hours=9)\n",
    "            temp_end_time = temp_end_time.to_pydatetime()\n",
    "        else:\n",
    "            temp_end_time = datetime.datetime.strptime(yymm + temp_end ,'%Y-%m-%d%H') + datetime.timedelta(hours = 9)         \n",
    "        \n",
    "        if temp_end_time > temp_start_time:\n",
    "            temp_end_time = temp_end_time\n",
    "        else: \n",
    "            temp_end_time = temp_end_time + relativedelta(months=1)\n",
    "            temp_start_time = temp_start_time\n",
    "        \n",
    "        if nextyear =='1231':\n",
    "            temp_start_time = temp_start_time + relativedelta(months=1)\n",
    "            temp_end_time = temp_end_time + relativedelta(months=1)\n",
    "        else:\n",
    "            temp_start_time = temp_start_time\n",
    "            temp_end_time = temp_end_time\n",
    "                    \n",
    "        # 바람    \n",
    "        temp_wind_f = re.search(pattern_wind, temp)\n",
    "        if temp_wind_f != None:\n",
    "            if temp_wind_f.group()[-1] == 'K':\n",
    "                temp_wind = temp[re.search(pattern_wind, temp).start()+1 : re.search(pattern_wind, temp).start()+8]\n",
    "                WDIR = temp_wind[0:3]\n",
    "                WSPD = temp_wind[3:5]\n",
    "                WG = '0'\n",
    "            else:\n",
    "                temp_wind = temp[re.search(pattern_wind, temp).start()+1 : re.search(pattern_wind, temp).start()+11]\n",
    "                WDIR = temp_wind[0:3]\n",
    "                WSPD = temp_wind[3:5]\n",
    "                WG = temp_wind[6:8]\n",
    "        else:\n",
    "            WDIR = None\n",
    "            WSPD = None\n",
    "            WG = None                \n",
    "        # 현천\n",
    "        temp_wc = re.search(pattern_wc, temp)\n",
    "        if temp_wc != None:\n",
    "            if temp_wc.group() == 'NSW':\n",
    "                WC = '0'\n",
    "            else:\n",
    "                WC = temp_wc.group()\n",
    "        else:\n",
    "            WC = '0'\n",
    "        # 구름    \n",
    "        temp_cloud = re.finditer(pattern_cloud, temp) \n",
    "        temp_tcloud = list(temp_cloud)\n",
    "        if len(temp_tcloud) == 3:\n",
    "            CLA_1LYR = temp[temp_tcloud[0].start() : temp_tcloud[0].start()+3]\n",
    "            BASE_1LYR = temp[temp_tcloud[0].start()+3 : temp_tcloud[0].start()+6]\n",
    "            CLA_2LYR = temp[temp_tcloud[1].start() : temp_tcloud[1].start()+3]\n",
    "            BASE_2LYR = temp[temp_tcloud[1].start()+3 : temp_tcloud[1].start()+6]\n",
    "            CLA_3LYR = temp[temp_tcloud[2].start() : temp_tcloud[2].start()+3]\n",
    "            BASE_3LYR = temp[temp_tcloud[2].start()+3 : temp_tcloud[2].start()+6]\n",
    "        elif len(temp_tcloud) == 2:\n",
    "            CLA_1LYR = temp[temp_tcloud[0].start() : temp_tcloud[0].start()+3]\n",
    "            BASE_1LYR = temp[temp_tcloud[0].start()+3 : temp_tcloud[0].start()+6]\n",
    "            CLA_2LYR = temp[temp_tcloud[1].start() : temp_tcloud[1].start()+3]\n",
    "            BASE_2LYR = temp[temp_tcloud[1].start()+3 : temp_tcloud[1].start()+6]\n",
    "            CLA_3LYR = '0'\n",
    "            BASE_3LYR = '400'\n",
    "        elif len(temp_tcloud) == 1:\n",
    "            CLA_1LYR = temp[temp_tcloud[0].start() : temp_tcloud[0].start()+3]\n",
    "            BASE_1LYR = temp[temp_tcloud[0].start()+3 : temp_tcloud[0].start()+6]\n",
    "            CLA_2LYR = '0'\n",
    "            BASE_2LYR = '400'\n",
    "            CLA_3LYR = '0'\n",
    "            BASE_3LYR = '400'\n",
    "        else: \n",
    "            CLA_1LYR = None\n",
    "            BASE_1LYR = None\n",
    "            CLA_2LYR = None\n",
    "            BASE_2LYR = None\n",
    "            CLA_3LYR = None\n",
    "            BASE_3LYR = None\n",
    "        # 시정  \n",
    "        if len(re.findall(pattern_cavok, temp)) == 0:\n",
    "            temp_vis = re.search(pattern_vis, temp)\n",
    "            if temp_vis != None:\n",
    "                VIS = temp[re.search(pattern_vis, temp).start()+1 : re.search(pattern_vis, temp).start()+5]\n",
    "            else:\n",
    "                VIS = None\n",
    "        else:\n",
    "            temp_vis = re.search(pattern_cavok, temp)\n",
    "            VIS = '9999'\n",
    "            CLA_1LYR = '0'\n",
    "            BASE_1LYR = '0'\n",
    "            CLA_2LYR = '0'\n",
    "            BASE_2LYR = '0'\n",
    "            CLA_3LYR = '0'\n",
    "            BASE_3LYR = '0'\n",
    "            \n",
    "\n",
    "        weather = [WDIR, WSPD, WG, VIS, WC, CLA_1LYR, BASE_1LYR, CLA_2LYR, BASE_2LYR, CLA_3LYR, BASE_3LYR]\n",
    "        dur = [chg[-1].group(), temp_start_time, temp_end_time]\n",
    "\n",
    "        Data = Data[:chg[-1].end()-6]\n",
    "        chg_iter = re.finditer(pattern_chg, Data)                # BECMG, TEMPO 들어간거 찾기\n",
    "        chg = list(chg_iter)\n",
    "\n",
    "        weathers[-i] = weather\n",
    "        durs[-i] = dur\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 7. 각각의 weather를 맞는 시간대의 TAF에 넣기\n",
    "    WW = TAF\n",
    "\n",
    "    for j in range(len(durs)):  \n",
    "        if durs[j][0] == 'BECMG':\n",
    "            durs[j][2] = end_time\n",
    "            temp_time = pd.date_range(start = durs[j][1], end = durs[j][2], freq = 'H')\n",
    "            Weather = [weathers[j]]\n",
    "            for k in range(len(temp_time)-1):\n",
    "                Weather.append(weathers[j])\n",
    "            Wx = pd.DataFrame(Weather, index = temp_time, columns = column)\n",
    "            issue_date = pd.DataFrame({'issue_time': [str(start_time)]*len(Wx)}, index = Wx.index)    # issue date 넣기\n",
    "            Wx = issue_date.join(Wx)\n",
    "            TAF.loc[str(durs[j][1]) : str(durs[j][2])] = Wx\n",
    "            WW = TAF.fillna(method = 'ffill')\n",
    "        else:\n",
    "            temp_time= pd.date_range(start = durs[j][1], end = durs[j][2], freq = 'H')\n",
    "            Weather = [weathers[j]]\n",
    "            for k in range(len(temp_time)-1):\n",
    "                Weather.append(weathers[j])\n",
    "            Wx = pd.DataFrame(Weather, index = temp_time, columns = column)\n",
    "            issue_date = pd.DataFrame({'issue_time': [str(start_time)]*len(Wx)}, index = Wx.index)    # issue date 넣기\n",
    "            Wx = issue_date.join(Wx)\n",
    "            TAF.loc[str(durs[j][1]) : str(durs[j][2])] = Wx\n",
    "            WW = TAF.fillna(method = 'ffill')  \n",
    "    \n",
    "    # 8.통합\n",
    "    TAF_data_2018[l] = WW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe19223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4760fa5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a46203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58aac9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96914ace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e6ada8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T04:19:29.960996Z",
     "start_time": "2021-07-21T04:19:28.656074Z"
    }
   },
   "outputs": [],
   "source": [
    "# csv로 저장    \n",
    "# pd.concat(TAF_data).to_csv('C:\\\\Users\\\\user\\\\proj\\\\TMA_Capacity\\\\data\\\\Weather\\\\TAF_data.csv')\n",
    "\n",
    "pd.concat(TAF_data_2018).to_csv('C:\\\\Users\\\\user\\\\proj\\\\TMA_Capacity\\\\data\\\\Weather\\\\TAF_data_2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526f7ccd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-05T01:53:37.244510Z",
     "start_time": "2021-07-05T01:53:37.215587Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "\n",
    "print(data.iloc[1000,0])\n",
    "TAF_data[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8324ada6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T04:17:50.588911Z",
     "start_time": "2021-07-21T04:17:50.545630Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taf\tRKSI\t2018-07-16 20:27:00\tTAF \\n AMD TAF \\n AMD RKSI 162025Z 1620/1724 24005KT 1800 BR FEW010 SCT030 TN23/1621Z TX30/1706Z TN23/1720Z \\n TEMPO 1620/1623 0600 FG OVC002 \\n BECMG 1623/1624 29006KT 6000 NSW \\n BECMG 1718/1719 26005KT 4200 BR \\n TEMPO 1719/1722 1200 \\n BECMG 1722/1723 7000 NSW\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>issue_time</th>\n",
       "      <th>WDIR</th>\n",
       "      <th>WSPD</th>\n",
       "      <th>WG</th>\n",
       "      <th>VIS</th>\n",
       "      <th>WC</th>\n",
       "      <th>CLA_1LYR</th>\n",
       "      <th>BASE_1LYR</th>\n",
       "      <th>CLA_2LYR</th>\n",
       "      <th>BASE_2LYR</th>\n",
       "      <th>CLA_3LYR</th>\n",
       "      <th>BASE_3LYR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-07-17 05:00:00</th>\n",
       "      <td>2018-07-17 05:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0600</td>\n",
       "      <td>FG</td>\n",
       "      <td>OVC</td>\n",
       "      <td>002</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-17 06:00:00</th>\n",
       "      <td>2018-07-17 05:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0600</td>\n",
       "      <td>FG</td>\n",
       "      <td>OVC</td>\n",
       "      <td>002</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-17 07:00:00</th>\n",
       "      <td>2018-07-17 05:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0600</td>\n",
       "      <td>FG</td>\n",
       "      <td>OVC</td>\n",
       "      <td>002</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-17 08:00:00</th>\n",
       "      <td>2018-07-17 05:00:00</td>\n",
       "      <td>290</td>\n",
       "      <td>06</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>OVC</td>\n",
       "      <td>002</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-17 09:00:00</th>\n",
       "      <td>2018-07-17 05:00:00</td>\n",
       "      <td>290</td>\n",
       "      <td>06</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>OVC</td>\n",
       "      <td>002</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-17 10:00:00</th>\n",
       "      <td>2018-07-17 05:00:00</td>\n",
       "      <td>290</td>\n",
       "      <td>06</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>OVC</td>\n",
       "      <td>002</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-17 11:00:00</th>\n",
       "      <td>2018-07-17 05:00:00</td>\n",
       "      <td>290</td>\n",
       "      <td>06</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>OVC</td>\n",
       "      <td>002</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-17 12:00:00</th>\n",
       "      <td>2018-07-17 05:00:00</td>\n",
       "      <td>290</td>\n",
       "      <td>06</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>OVC</td>\n",
       "      <td>002</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-17 13:00:00</th>\n",
       "      <td>2018-07-17 05:00:00</td>\n",
       "      <td>290</td>\n",
       "      <td>06</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>OVC</td>\n",
       "      <td>002</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-17 14:00:00</th>\n",
       "      <td>2018-07-17 05:00:00</td>\n",
       "      <td>290</td>\n",
       "      <td>06</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>OVC</td>\n",
       "      <td>002</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-17 15:00:00</th>\n",
       "      <td>2018-07-17 05:00:00</td>\n",
       "      <td>290</td>\n",
       "      <td>06</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>OVC</td>\n",
       "      <td>002</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-17 16:00:00</th>\n",
       "      <td>2018-07-17 05:00:00</td>\n",
       "      <td>290</td>\n",
       "      <td>06</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>OVC</td>\n",
       "      <td>002</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-17 17:00:00</th>\n",
       "      <td>2018-07-17 05:00:00</td>\n",
       "      <td>290</td>\n",
       "      <td>06</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>OVC</td>\n",
       "      <td>002</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-17 18:00:00</th>\n",
       "      <td>2018-07-17 05:00:00</td>\n",
       "      <td>290</td>\n",
       "      <td>06</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>OVC</td>\n",
       "      <td>002</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-17 19:00:00</th>\n",
       "      <td>2018-07-17 05:00:00</td>\n",
       "      <td>290</td>\n",
       "      <td>06</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>OVC</td>\n",
       "      <td>002</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-17 20:00:00</th>\n",
       "      <td>2018-07-17 05:00:00</td>\n",
       "      <td>290</td>\n",
       "      <td>06</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>OVC</td>\n",
       "      <td>002</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-17 21:00:00</th>\n",
       "      <td>2018-07-17 05:00:00</td>\n",
       "      <td>290</td>\n",
       "      <td>06</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>OVC</td>\n",
       "      <td>002</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-17 22:00:00</th>\n",
       "      <td>2018-07-17 05:00:00</td>\n",
       "      <td>290</td>\n",
       "      <td>06</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>OVC</td>\n",
       "      <td>002</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-17 23:00:00</th>\n",
       "      <td>2018-07-17 05:00:00</td>\n",
       "      <td>290</td>\n",
       "      <td>06</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>OVC</td>\n",
       "      <td>002</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-18 00:00:00</th>\n",
       "      <td>2018-07-17 05:00:00</td>\n",
       "      <td>290</td>\n",
       "      <td>06</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>OVC</td>\n",
       "      <td>002</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-18 01:00:00</th>\n",
       "      <td>2018-07-17 05:00:00</td>\n",
       "      <td>290</td>\n",
       "      <td>06</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>OVC</td>\n",
       "      <td>002</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-18 02:00:00</th>\n",
       "      <td>2018-07-17 05:00:00</td>\n",
       "      <td>290</td>\n",
       "      <td>06</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>OVC</td>\n",
       "      <td>002</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-18 03:00:00</th>\n",
       "      <td>2018-07-17 05:00:00</td>\n",
       "      <td>260</td>\n",
       "      <td>05</td>\n",
       "      <td>0</td>\n",
       "      <td>4200</td>\n",
       "      <td>BR</td>\n",
       "      <td>OVC</td>\n",
       "      <td>002</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-18 04:00:00</th>\n",
       "      <td>2018-07-17 05:00:00</td>\n",
       "      <td>260</td>\n",
       "      <td>05</td>\n",
       "      <td>0</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "      <td>OVC</td>\n",
       "      <td>002</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-18 05:00:00</th>\n",
       "      <td>2018-07-17 05:00:00</td>\n",
       "      <td>260</td>\n",
       "      <td>05</td>\n",
       "      <td>0</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "      <td>OVC</td>\n",
       "      <td>002</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-18 06:00:00</th>\n",
       "      <td>2018-07-17 05:00:00</td>\n",
       "      <td>260</td>\n",
       "      <td>05</td>\n",
       "      <td>0</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "      <td>OVC</td>\n",
       "      <td>002</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-18 07:00:00</th>\n",
       "      <td>2018-07-17 05:00:00</td>\n",
       "      <td>260</td>\n",
       "      <td>05</td>\n",
       "      <td>0</td>\n",
       "      <td>7000</td>\n",
       "      <td>0</td>\n",
       "      <td>OVC</td>\n",
       "      <td>002</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-18 08:00:00</th>\n",
       "      <td>2018-07-17 05:00:00</td>\n",
       "      <td>260</td>\n",
       "      <td>05</td>\n",
       "      <td>0</td>\n",
       "      <td>7000</td>\n",
       "      <td>0</td>\n",
       "      <td>OVC</td>\n",
       "      <td>002</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-18 09:00:00</th>\n",
       "      <td>2018-07-17 05:00:00</td>\n",
       "      <td>260</td>\n",
       "      <td>05</td>\n",
       "      <td>0</td>\n",
       "      <td>7000</td>\n",
       "      <td>0</td>\n",
       "      <td>OVC</td>\n",
       "      <td>002</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              issue_time  WDIR  WSPD    WG   VIS  WC CLA_1LYR  \\\n",
       "2018-07-17 05:00:00  2018-07-17 05:00:00  None  None  None  0600  FG      OVC   \n",
       "2018-07-17 06:00:00  2018-07-17 05:00:00  None  None  None  0600  FG      OVC   \n",
       "2018-07-17 07:00:00  2018-07-17 05:00:00  None  None  None  0600  FG      OVC   \n",
       "2018-07-17 08:00:00  2018-07-17 05:00:00   290    06     0  6000   0      OVC   \n",
       "2018-07-17 09:00:00  2018-07-17 05:00:00   290    06     0  6000   0      OVC   \n",
       "2018-07-17 10:00:00  2018-07-17 05:00:00   290    06     0  6000   0      OVC   \n",
       "2018-07-17 11:00:00  2018-07-17 05:00:00   290    06     0  6000   0      OVC   \n",
       "2018-07-17 12:00:00  2018-07-17 05:00:00   290    06     0  6000   0      OVC   \n",
       "2018-07-17 13:00:00  2018-07-17 05:00:00   290    06     0  6000   0      OVC   \n",
       "2018-07-17 14:00:00  2018-07-17 05:00:00   290    06     0  6000   0      OVC   \n",
       "2018-07-17 15:00:00  2018-07-17 05:00:00   290    06     0  6000   0      OVC   \n",
       "2018-07-17 16:00:00  2018-07-17 05:00:00   290    06     0  6000   0      OVC   \n",
       "2018-07-17 17:00:00  2018-07-17 05:00:00   290    06     0  6000   0      OVC   \n",
       "2018-07-17 18:00:00  2018-07-17 05:00:00   290    06     0  6000   0      OVC   \n",
       "2018-07-17 19:00:00  2018-07-17 05:00:00   290    06     0  6000   0      OVC   \n",
       "2018-07-17 20:00:00  2018-07-17 05:00:00   290    06     0  6000   0      OVC   \n",
       "2018-07-17 21:00:00  2018-07-17 05:00:00   290    06     0  6000   0      OVC   \n",
       "2018-07-17 22:00:00  2018-07-17 05:00:00   290    06     0  6000   0      OVC   \n",
       "2018-07-17 23:00:00  2018-07-17 05:00:00   290    06     0  6000   0      OVC   \n",
       "2018-07-18 00:00:00  2018-07-17 05:00:00   290    06     0  6000   0      OVC   \n",
       "2018-07-18 01:00:00  2018-07-17 05:00:00   290    06     0  6000   0      OVC   \n",
       "2018-07-18 02:00:00  2018-07-17 05:00:00   290    06     0  6000   0      OVC   \n",
       "2018-07-18 03:00:00  2018-07-17 05:00:00   260    05     0  4200  BR      OVC   \n",
       "2018-07-18 04:00:00  2018-07-17 05:00:00   260    05     0  1200   0      OVC   \n",
       "2018-07-18 05:00:00  2018-07-17 05:00:00   260    05     0  1200   0      OVC   \n",
       "2018-07-18 06:00:00  2018-07-17 05:00:00   260    05     0  1200   0      OVC   \n",
       "2018-07-18 07:00:00  2018-07-17 05:00:00   260    05     0  7000   0      OVC   \n",
       "2018-07-18 08:00:00  2018-07-17 05:00:00   260    05     0  7000   0      OVC   \n",
       "2018-07-18 09:00:00  2018-07-17 05:00:00   260    05     0  7000   0      OVC   \n",
       "\n",
       "                    BASE_1LYR CLA_2LYR BASE_2LYR CLA_3LYR BASE_3LYR  \n",
       "2018-07-17 05:00:00       002        0       400        0       400  \n",
       "2018-07-17 06:00:00       002        0       400        0       400  \n",
       "2018-07-17 07:00:00       002        0       400        0       400  \n",
       "2018-07-17 08:00:00       002        0       400        0       400  \n",
       "2018-07-17 09:00:00       002        0       400        0       400  \n",
       "2018-07-17 10:00:00       002        0       400        0       400  \n",
       "2018-07-17 11:00:00       002        0       400        0       400  \n",
       "2018-07-17 12:00:00       002        0       400        0       400  \n",
       "2018-07-17 13:00:00       002        0       400        0       400  \n",
       "2018-07-17 14:00:00       002        0       400        0       400  \n",
       "2018-07-17 15:00:00       002        0       400        0       400  \n",
       "2018-07-17 16:00:00       002        0       400        0       400  \n",
       "2018-07-17 17:00:00       002        0       400        0       400  \n",
       "2018-07-17 18:00:00       002        0       400        0       400  \n",
       "2018-07-17 19:00:00       002        0       400        0       400  \n",
       "2018-07-17 20:00:00       002        0       400        0       400  \n",
       "2018-07-17 21:00:00       002        0       400        0       400  \n",
       "2018-07-17 22:00:00       002        0       400        0       400  \n",
       "2018-07-17 23:00:00       002        0       400        0       400  \n",
       "2018-07-18 00:00:00       002        0       400        0       400  \n",
       "2018-07-18 01:00:00       002        0       400        0       400  \n",
       "2018-07-18 02:00:00       002        0       400        0       400  \n",
       "2018-07-18 03:00:00       002        0       400        0       400  \n",
       "2018-07-18 04:00:00       002        0       400        0       400  \n",
       "2018-07-18 05:00:00       002        0       400        0       400  \n",
       "2018-07-18 06:00:00       002        0       400        0       400  \n",
       "2018-07-18 07:00:00       002        0       400        0       400  \n",
       "2018-07-18 08:00:00       002        0       400        0       400  \n",
       "2018-07-18 09:00:00       002        0       400        0       400  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_columns = None\n",
    "\n",
    "print(data_2018.iloc[1000,0])\n",
    "TAF_data_2018[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb6e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# 12월 31일 넘어가면서 한달씩 늘리는거 다시 고치기\n",
    "# 구름에 CB있는거 넣을수 있도록\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
