{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f324c44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from scklearn.preprocessing import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2925ea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# options\n",
    "pd.set_option('max_columns',100)\n",
    "plt.style.use('fivethirtyeight')\n",
    "warnings.simplefilter('ignore')\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3126ab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data dirctory\n",
    "data_dir = Path('../data/')\n",
    "data_file = data_dir / 'Data_raw.csv'\n",
    "\n",
    "# Data\n",
    "# 0:AAR / 1:EAD / 2:ADR / 3:EDD는 고정  , 나머지는 순서 상관 없음\n",
    "Data = pd.read_csv(data_file, index_col=0)\n",
    "ColumnName = Data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4e3079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d6f3ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564915a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaf599e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bc3500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eab12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "\n",
    "# decision tree류의 알고리즘은 Scaling(standardization, normalization)이 큰 의미 X\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(df[num_cols])\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, np.log1p(df[target_col]))\n",
    "df[pred_col] = np.expm1(lr.predict(X))\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(df[num_cols])\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, np.log1p(df[target_col]))\n",
    "df[pred_col] = np.expm1(lr.predict(X))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfa3856",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binning\n",
    "\n",
    "#어떤 feature를 n개의 그룹으로 나누고, 그것을 새로운 categorical data로 넣는 것\n",
    "\n",
    "\"\"\"\n",
    "df['time_bin'] = pd.qcut(df['time'], 4, labels=False)\n",
    "sns.pairplot(data=df, vars=['time', 'time_bin'], size=4, plot_kws={'alpha': .5})\n",
    "\n",
    "\n",
    "X = pd.concat([df[num_cols], pd.get_dummies(pd.qcut(df['time'], 4, labels=False))], axis=1)    \n",
    "# get_dummies 는 one-hot encoding해주는 것(decision tree 계열을 안 하는게 보통 더 좋은 결과를 냄)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, np.log1p(df[target_col]))\n",
    "df[pred_col] = np.expm1(lr.predict(X))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a841b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial Regression\n",
    "\n",
    "# 연속적인 몇개의 feature들을 조합해서 새로운 feature를 만드는 것 (overfitting 위험 O)\n",
    "\n",
    "\"\"\"\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(2)        # 2차(x^2, x1 * x2 등) 까지만 만들겠다\n",
    "X = poly.fit_transform(df[num_cols])\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, np.log1p(df[target_col]))\n",
    "df[pred_col] = np.expm1(lr.predict(X))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7e2b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for NaN values and removing constant features in the training data\n",
    "# Removing duplicated columns\n",
    "# Drop Sparse Data\n",
    "\n",
    "### Add Features\n",
    "# Sumzeros and Sumvalues\n",
    "# Other Aggregates\n",
    "# K-Means\n",
    "# PCA : Principal component analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecf6521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788bc154",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
